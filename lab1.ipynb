{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ff1tWjz9IMU"
      },
      "source": [
        "# Opinion Mining & Sentiment Analysis: Lab Activities\n",
        "\n",
        "**Text Mining unit**\n",
        "\n",
        "_Prof. Gianluca Moro, Prof. Giacomo Frisoni, DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVEJNfK9IMV"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import external libraries (thus verifying they are correctly installed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mahnniQH9IMV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqGAJAwE9IMY"
      },
      "source": [
        "If using IPython/Jupyter, run the following to render plots inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4F4jCZtw9IMY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XQSMiSN9IMa"
      },
      "source": [
        "Set some options in pandas for printing DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p72mmuD39IMb"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_colwidth = 100\n",
        "pd.options.display.precision = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naIH999P9IMd"
      },
      "source": [
        "Define a utility function to download data files if they are not already present in working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N8v0EsMy9IMd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPuiZa99IMf"
      },
      "source": [
        "## Activity 1: Opinion Mining on airline tweets\n",
        "\n",
        "🎯 We want to evaluate how much customers are satisfied of airline companies based on Twitter (X) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m5ZiyOi7rMO"
      },
      "source": [
        "### Activity plan\n",
        "\n",
        "1. Collect tweets mentioning airline companies\n",
        "2. Define lists of opinion keywords\n",
        "3. Evaluate sentiment of each tweet\n",
        "4. Summarize sentiment for each airline company\n",
        "5. Extract customer satisfaction for companies from the ACSI website\n",
        "6. Compare scores estimated from Twitter with those extracted from ACSI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYYAQJN9IMj"
      },
      "source": [
        "### Collect tweets citing airline companies\n",
        "\n",
        "Recent tweets matching a given query can be searched using the Twitter Search API; many libraries exist for Python and other languages providing easy access to the API\n",
        "\n",
        "`TweePy` is the most popular package, suggested by the official [Twitter (X) Developer Platform tutorial](https://developer.twitter.com/en/docs/tutorials/tweeting-media-v2), installable with `pip install tweepy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OoGLa6FsR9P",
        "outputId": "8292626f-44bf-40c3-b556-cafaa3957c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy==4.14.0 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from tweepy==4.14.0) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from tweepy==4.14.0) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from tweepy==4.14.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jcbraz/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy==4.14.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HORmDG1V9IMj"
      },
      "source": [
        "#### Creating a Twitter application\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2nZqkKV1vu5"
      },
      "source": [
        "In order to use Twitter APIs you need access keys and tokens: follow these steps to obtain them\n",
        "\n",
        "1. Go to the [Twitter Developer Portal Projects & Apps page](https://developer.twitter.com/en/apps) and login with your Twitter account\n",
        "2. Go to your dashboard and create a standalone or project-related app; fill the form with short descriptive values\n",
        "  *   Choose the name you prefer, e.g., \"BBS-TextMining-Lab\"\n",
        "  *   Make sure to copy the provided API Key (_Consumer Key_), API Key Secret (_Consumer Secret_), and Bearer Token\n",
        "  *   Then, click on \"App Settings\"\n",
        "  *   Go to the \"Keys and Tokens\" tab, and click on the \"Generate\" button next to \"Access Token and Secret\"; copy the provided values\n",
        "\n",
        "Store your secrets (i.e., bearer_token, consumer_key, consumer_secret, access_token, access_token_secret) safely in Colab (left tab); this feature has been released in November 2023 [(Source)](https://x.com/GoogleColab/status/1719798406195867814?s=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFfbINP22IJH"
      },
      "source": [
        "Unfortunately, from Nov. 9 2023, Twitter APIs do not longer support free access to tweets [(Source)](https://twitter.com/XDevelopers/status/1621026986784337922)\n",
        "\n",
        "Free plans only support thresholded POST and DELETE operations, and SELF-USER LOOKUP\n",
        "\n",
        "To manage tweets completely and retrieve data, you have to upgrade to the Basic Level. At the time of writing, $100/month\n",
        "\n",
        "We will show a Tweepy example for free SELF-USER LOOKUP;\n",
        "[complete Tweepy API documentation](https://docs.tweepy.org/en/stable/api.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBhW_i09IMk"
      },
      "source": [
        "#### Authenticating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3nCEDR03tCjP"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtweepy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m      5\u001b[0m     bearer_token \u001b[38;5;241m=\u001b[39m userdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbearer_token\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     consumer_key \u001b[38;5;241m=\u001b[39m userdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsumer_key\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     access_token_secret \u001b[38;5;241m=\u001b[39m userdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_token_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from google.colab import userdata\n",
        "\n",
        "client = tweepy.Client(\n",
        "    bearer_token = userdata.get(\"bearer_token\"),\n",
        "    consumer_key = userdata.get(\"consumer_key\"),\n",
        "    consumer_secret = userdata.get(\"consumer_secret\"),\n",
        "    access_token = userdata.get(\"access_token\"),\n",
        "    access_token_secret = userdata.get(\"access_token_secret\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVxdiCjZ5swk"
      },
      "source": [
        "#### Data collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU5TBDVJ52Ft",
        "outputId": "9897747d-ad94-446c-82c2-9d69efc7e936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Response(data=<User id=405020606 name=Giacomo Frisoni username=GiacomoFrisoni>, includes={}, errors=[], meta={})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Self-user lookup\n",
        "client.get_me()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CVMZx5UHoZ9m"
      },
      "outputs": [],
      "source": [
        "#@title #####If you have access to a Basic Plan attached to a Project-related App...\n",
        "\n",
        "# Replace with your own search query\n",
        "query = 'from:delta -is:retweet'\n",
        "\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=['created_at'], max_results=100)\n",
        "\n",
        "for tweet in tweets.data:\n",
        "    print(tweet.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfbPhaw9IM4"
      },
      "source": [
        "### Using pre-collected tweets\n",
        "\n",
        "For convenience, we provide a set of precollected tweets about the airline companies as an alternative to latest tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rJXE4I_I9IM4"
      },
      "outputs": [],
      "source": [
        "download(\"tweets.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/tweets.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkDuqRx9IMf"
      },
      "source": [
        "This is a list of the Twitter (X) accounts of airline companies taken into consideration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EZwtwx3F9IMg"
      },
      "outputs": [],
      "source": [
        "airlines = [\n",
        "    \"delta\",\n",
        "    \"americanair\",\n",
        "    \"jetblue\",\n",
        "    \"southwestair\",\n",
        "    \"united\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sEkMrRK9IM6"
      },
      "source": [
        "The ZIP archive contains a `company_name.txt` file for each airline company, each with a list of tweets (one per line)\n",
        "\n",
        "We load data into a dict, mapping the name of each company to the list of its relevant tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MQzbR0hz9IM7"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "archive_tweets = {}\n",
        "with ZipFile(\"tweets.zip\") as zipf:\n",
        "    for airline in airlines:\n",
        "        with zipf.open(airline + \".txt\") as f:\n",
        "            archive_tweets[airline] = list(line.decode().strip() for line in f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScC5ge499IM8"
      },
      "source": [
        "You can read for example some tweets about Delta airlines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rg0Nu9e9IM9",
        "outputId": "711fac30-4b2b-40b4-bf54-50a563a542f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings vs Rangers in NY - http://t.co/JXBc5kDXnZ\"RT',\n",
              " '@AneetharPweety am @delta state buh on ma way to benin city now',\n",
              " 'RT @iamdiddy: If you’re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lounge at @Delta terminal at JFK. http://t.co/…']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "archive_tweets[\"delta\"][:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-dWEteC9IM-"
      },
      "source": [
        "In the following we will work on these `archive_tweets`, replace that in the line below with `current_tweets` if you want to use downloaded tweets instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qO407nji9IM-"
      },
      "outputs": [],
      "source": [
        "tweets = archive_tweets # current_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khZAVoZV9INA"
      },
      "source": [
        "Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of Python\n",
        "\n",
        "To better deal with them later, we represents tweets into a pandas DataFrame with two columns\n",
        "- a `text` column with the text of the tweet\n",
        "- an `airline` column with the airline each tweet refers to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6_q-5J0N9INA"
      },
      "outputs": [],
      "source": [
        "tweets = pd.DataFrame(\n",
        "    {\"airline\": airline, \"text\": text}\n",
        "    for airline, tweetlist in tweets.items()\n",
        "    for text in tweetlist\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "BVxwWYH79INC",
        "outputId": "cf967e1e-a670-42ba-dffb-441d6ec55e38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>delta</td>\n",
              "      <td>\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delta</td>\n",
              "      <td>@AneetharPweety am @delta state buh on ma way to benin city now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>delta</td>\n",
              "      <td>RT @iamdiddy: If you’re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline  \\\n",
              "0   delta   \n",
              "1   delta   \n",
              "2   delta   \n",
              "\n",
              "                                                                                                  text  \n",
              "0  \"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...  \n",
              "1                                      @AneetharPweety am @delta state buh on ma way to benin city now  \n",
              "2  RT @iamdiddy: If you’re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKrg7s8f9INF"
      },
      "source": [
        "### Estimating sentiment using lists of opinion words\n",
        "\n",
        "Several methods and algorithms have been proposed in literature to estimate the sentiment of a document (or sentence), usually quite complex\n",
        "\n",
        "To get started, we will use a simple lexicon-based method which assigns a score by counting known positive and negative words in each tweet\n",
        "\n",
        "Hu and Liu made available for download a list of about 6,800 words labeled as either positive or negative\n",
        "\n",
        "- **Positive:** love, best, cool, great, good, amazing, ...\n",
        "- **Negative:** hate, worst, sucks, awful, nightmare, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrgWberF9INF"
      },
      "source": [
        "We write:\n",
        "- a function to process word lists, ignoring lines either empty or starting with \";\" (comments)\n",
        "- another function using the first one to get a set of words contained in a named file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BBxH-BSW9ING"
      },
      "outputs": [],
      "source": [
        "def scan_hu_liu(f):\n",
        "    for line in f:\n",
        "        line = line.decode(errors=\"ignore\").strip() # strip() function removes spaces at the beginning and at the end of the string\n",
        "        if line and not line.startswith(\";\"):\n",
        "            yield line\n",
        "\n",
        "def load_hu_liu(filename):\n",
        "    with open(filename, \"rb\") as f:  # b binary mode\n",
        "        return set(scan_hu_liu(f)) # set(...) is the build function to create a new Python set {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqbslQd69INI"
      },
      "source": [
        "We then download the two sets (one for positive words and one for negative words) and use the latter function to load them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAfuoln99INI",
        "outputId": "818faa9a-ce97-464f-f399-823f575b725b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive words\n",
            "{'inspirational', 'hardy', 'superior', 'bargain', 'amity', 'superiority', 'bloom', 'merry', 'civility', 'stimulates', 'striking', 'correct', 'resolute', 'trustworthiness', 'decisiveness', 'abundant', 'marveled', 'gusto', 'premier', 'purposeful', 'abundance', 'lavish', 'splendor', 'ecstatically', 'supurbly', 'supreme', 'suavely', 'elegance', 'erudite', 'vouchsafe', 'revelation', 'punctual', 'tempting', 'exceeded', 'eventful', 'solicitously', 'ethical', 'rock-star', 'clever', 'well-behaved', 'happier', 'harmonize', 'honored', 'low-cost', 'handsomely', 'swift', 'fresh', 'momentous', 'appreciatively', 'admiring', 'sensations', 'impartially', 'nicer', 'astounding', 'apotheosis', 'impartial', 'exciting', 'enjoyment', 'captivate', 'agilely', 'reform', 'thoughtfully', 'masters', 'excellent', 'complement', 'high-quality', 'pampers', 'marvelousness', 'thank', 'inestimably', 'agreeably', 'angelic', 'strongest', 'affability', 'zeal', 'affable', 'uncomplicated', 'happiness', 'awards', 'cure-all', 'lucid', 'astound', 'subsidizing', 'pleasurable', 'navigable', 'ready', 'fond', 'hilarious', 'winnable', 'affection', 'affirm', 'god-send', 'unwavering', 'promoter', 'compassion', 'proud', 'genuine', 'affably', 'willingly', 'plentiful', 'enhances', 'enrichment', 'enjoyably', 'excites', 'fine', 'enticingly', 'thrill', 'romantically', 'satisfied', 'diligence', 'wow', 'replaceable', 'kudos', 'speedy', 'youthful', 'breakthrough', 'agreeable', 'benevolent', 'enjoyable', 'thriving', 'adoring', 'glimmering', 'convient', 'excelent', 'defender', 'hero', 'spellbound', 'liberation', 'unselfish', 'sensationally', 'eloquently', 'successful', 'kindness', 'unrestricted', 'stunning', 'unconditional', 'sparkling', 'illuminating', 'thrive', 'openness', 'thrillingly', 'savior', 'ample', 'supremely', 'mesmerizingly', 'dead-cheap', 'cornerstone', 'tremendously', 'quaint', 'classic', 'successes', 'virtuous', 'comely', 'accolade', 'steadiness', 'heartwarming', 'gleefully', 'faster', 'restored', 'galore', 'chivalry', 'enlighten', 'light-hearted', 'favorited', 'beauteous', 'responsibly', 'peaceable', 'luckiness', 'warmhearted', 'proven', 'ingenious', 'keenly', 'glimmer', 'quieter', 'rapport', 'fashionable', 'trump', 'thumbs-up', 'convienient', 'flattering', 'truthfulness', 'wise', 'upliftment', 'perseverance', 'saint', 'prestige', 'prominent', 'consistent', 'savvy', 'fair', 'dashing', 'loyalty', 'fascinate', 'whoa', 'delightful', 'wondrous', 'ovation', 'prospros', 'finely', 'spacious', 'satisfy', 'breeze', 'righten', 'stable', 'comfortably', 'stupendous', 'reforms', 'buoyant', 'gifted', 'cuteness', 'ingenuity', 'paradise', 'healthful', 'law-abiding', 'lucky', 'sufficiently', 'enchantingly', 'striving', 'credible', 'joyous', 'clarity', 'gaily', 'opulent', 'a+', 'humour', 'poise', 'recover', 'work', 'well-connected', 'palatial', 'steadfastly', 'champ', 'upgradable', 'fervent', 'honoring', 'simplifying', 'praiseworthy', 'tenacity', 'neat', 'skilled', 'comforting', 'unquestionably', 'accommodative', 'precise', 'perfect', 'bravo', 'witty', 'tender', 'pleasantly', 'gems', 'skillfully', 'vigilant', 'appeal', 'positively', 'razor-sharp', 'euphoria', 'sharpest', 'bravery', 'astonished', 'supple', 'handy', 'courageousness', 'prettily', 'adoringly', 'enterprising', 'fav', 'cleared', 'futuristic', 'impressively', 'handsome', 'obsession', 'splendid', 'admirably', 'magical', 'succes', 'dignify', 'virtue', 'optimal', 'revolutionized', 'valiant', 'eases', 'resilient', 'patience', 'gratify', 'assuredly', 'astonish', 'flawless', 'amazes', 'geeky', 'durable', 'fastest-growing', 'avidly', 'revitalize', 'luckier', 'gleeful', 'popular', 'sweetly', 'adaptable', 'distinction', 'rightness', 'straighten', 'foremost', 'regal', 'rosy', 'obsessions', 'unaffected', 'eulogize', 'prudence', 'gutsy', 'valuable', 'steadfastness', 'principled', 'well-established', 'fecilitous', 'pain-free', 'jollify', 'champion', 'conciliate', 'fulfillment', 'courageous', 'impeccable', 'panoramic', 'qualify', 'perfectly', 'prefers', 'bonuses', 'overtook', 'luxuriously', 'thrift', 'earnestness', 'trusted', 'lovable', 'convenient', 'issue-free', 'greatness', 'encouragingly', 'faithfulness', 'astoundingly', 'glory', 'gorgeous', 'impressiveness', 'amenable', 'comfy', 'proper', 'masterfully', 'fondly', 'enjoys', 'enticed', 'regard', 'attentive', 'agility', 'undisputable', 'darling', 'angel', 'evaluative', 'simplified', 'exhilarating', 'accolades', 'mesmerize', 'unforgettable', 'solidarity', 'sexy', 'agile', 'rapid', 'stimulative', 'continuity', 'envious', 'breathlessness', 'rejoicing', 'imaculate', 'fabulous', 'pros', 'abound', 'preferably', 'reclaim', 'monumentally', 'fave', 'raptureous', 'unbeatable', 'ilu', 'acclaim', 'congratulation', 'gallant', 'luxury', 'humorous', 'adore', 'assurances', 'humble', 'contribution', 'defeats', 'beautifully', 'endorsed', 'smarter', 'reasoned', 'felicity', 'amiabily', 'miraculousness', 'thumb-up', 'brilliant', 'entrancing', 'jovial', 'outdo', 'stimulate', 'suave', 'graciously', 'articulate', 'genius', 'fashionably', 'dazzled', 'harmonious', 'enviously', 'smartest', 'wows', 'world-famous', 'amenity', 'dumbfounding', 'admirer', 'works', 'credence', 'solicitous', 'achievable', 'brave', 'supportive', 'best', 'eye-catching', 'improvements', 'pleasing', 'proving', 'courtly', 'reconciliation', 'shiny', 'excellency', 'constructive', 'nicely', 'well-educated', 'fearlessly', 'congratulatory', 'savings', 'infallible', 'righteously', 'better-than-expected', 'benifits', 'favor', 'achievement', 'friendliness', 'deft', 'graceful', 'praising', 'undisputed', 'politeness', 'shimmering', 'skill', 'enthusiastically', 'nobly', 'inspiring', 'lively', 'self-sufficient', 'reputable', 'smitten', 'contentment', 'cohere', 'compliant', 'neatest', 'seamless', 'effectively', 'delicacy', 'vouch', 'awed', 'prosperous', 'user-replaceable', 'significant', 'diversified', 'victorious', 'overture', 'marvelously', 'promised', 'danke', 'exhilarate', 'love', 'realistic', 'evocative', 'sociable', 'splendidly', 'strong', 'illumine', 'feat', 'unparalleled', 'trustingly', 'willingness', 'ingenuous', 'astonishingly', 'hotcake', 'cool', 'preferable', 'qualified', 'upscale', 'well-balanced', 'unrivaled', 'affluence', 'nurturing', 'glorious', 'invaluablely', 'breathtaking', 'endearing', 'eagerness', 'beloved', 'godlike', 'guarantee', 'effectual', 'thoughtfulness', 'appreciable', 'intelligible', 'joyfully', 'appropriate', 'prodigious', 'revel', 'smiling', 'sumptuousness', 'satisified', 'support', 'won', 'devout', 'pre-eminent', 'outperforming', 'redeem', 'stainless', 'altruistically', 'cooperatively', 'accurate', 'plusses', 'congratulations', 'fearless', 'feisty', 'swank', 'resound', 'playfully', 'merrily', 'infallibility', 'jaw-droping', 'tantalizingly', 'attraction', 'subsidized', 'enthusiast', 'well-positioned', 'best-selling', 'rejoice', 'talents', 'smilingly', 'excitedness', 'streamlined', 'fascinating', 'marvellous', 'sagacity', 'receptive', 'clearly', 'entertaining', 'cost-saving', 'state-of-the-art', 'earnest', 'pampered', 'top', 'picturesque', 'daring', 'prefer', 'succeeds', 'flatter', 'luminous', 'persevere', 'luxuriant', 'accomplishments', 'exquisitely', 'audibly', 'acclamation', 'adorable', 'cashbacks', 'outdone', 'geekier', 'top-quality', 'revives', 'idolize', 'time-honored', 'well-regarded', 'eye-catch', 'convenience', 'gold', 'delight', 'integral', 'trendy', 'crisp', 'peach', 'triumphal', 'clear-cut', 'meticulous', 'amiability', 'refreshing', 'positives', 'painless', 'heartily', 'swankiest', 'greatest', 'generosity', 'swanky', 'warm', 'amazingly', 'smoothest', 'eminence', 'adaptive', 'distinguished', 'secure', 'improves', 'good', 'charm', 'modest', 'righteousness', 'staunchness', 'trusting', 'happily', 'satisfying', 'phenomenally', 'affordable', 'illustrious', 'rockstar', 'everlasting', 'fast-paced', 'lovely', 'lighter', 'spontaneous', 'eloquent', 'cooperative', 'responsive', 'great', 'dominates', 'restructure', 'stylized', 'smoother', 'easy', 'uphold', 'high-spirited', 'manageable', 'gracefully', 'adequate', 'salute', 'vigilance', 'feature-rich', 'boom', 'supporting', 'mature', 'peerless', 'ebulliently', 'trouble-free', 'miraculously', 'desiring', 'aver', 'beckons', 'liberty', 'freed', 'nourishment', 'protect', 'fabulously', 'sharp', 'raptureously', 'benefit', 'easygoing', 'perfection', 'wonderful', 'survivor', 'amusingly', 'excitingly', 'soundly', 'overtaking', 'thinner', 'novelty', 'beneficent', 'unmatched', 'rewarding', 'self-respect', 'tantalize', 'outwit', 'remedy', 'non-violence', 'harmony', 'illuminati', 'pleasure', 'smartly', 'stabilize', 'improvement', 'truthfully', 'sustainable', 'economical', 'entertain', 'pure', 'effectiveness', 'enthuse', 'outperforms', 'outstandingly', 'honorable', 'inestimable', 'spectacular', 'sensational', 'intriguing', 'exaltedly', 'well-informed', 'well-received', 'intelligence', 'dynamic', 'worth-while', 'advantageously', 'unencumbered', 'adventurous', 'sweeten', 'enthral', 'charitable', 'outshine', 'consummate', 'respectfully', 'sublime', 'freedom', 'deginified', 'talent', 'cherished', 'reward', 'bliss', 'spiritual', 'modesty', 'pretty', 'trusty', 'audible', 'maturity', 'shimmeringly', 'temptingly', 'excite', 'robust', 'merriment', 'reassurance', 'complements', 'effortlessly', 'rapture', 'balanced', 'hearten', 'examplary', 'glorify', 'rejuvenated', 'protective', 'advantageous', 'fortuitously', 'charisma', 'stylishly', 'favorable', 'flawlessly', 'delighted', 'graciousness', 'promises', 'sincerity', 'dote', 'softer', 'futurestic', 'handily', 'sensitive', 'realizable', 'rectifying', 'long-lasting', 'enhanced', 'classy', 'uplifting', 'competitive', 'gumption', 'outsmart', 'energy-efficient', 'fertile', 'generously', 'rejuvenate', 'well-being', 'astounded', 'defeating', 'cherub', 'effusively', 'glitter', 'decency', 'leads', 'revolutionize', 'traction', 'reverently', 'correctly', 'cleanliness', 'swankier', 'friendly', 'guidance', 'sumptuously', 'examplar', 'extoll', 'capable', 'hale', 'stellarly', 'ardent', 'gallantly', 'educated', 'richly', 'fancy', 'commend', 'fame', 'acumen', 'originality', 'abounds', 'compactly', 'endorses', 'excellence', 'solace', 'succeeding', 'dirt-cheap', 'holy', 'peaceful', 'peppy', 'respectful', 'sufficient', 'miraculous', 'mightily', 'smile', 'aspiration', 'silent', 'hottest', 'marvels', 'incredibly', 'propitious', 'trustworthy', 'humility', 'soothe', 'luster', 'revere', 'brighter', 'foresight', 'luxurious', 'chic', 'overjoyed', 'beckoned', 'eased', 'elatedly', 'incredible', 'expeditiously', 'chivalrous', 'tranquil', 'self-determination', 'stupendously', 'eager', 'enjoyed', 'rock-stars', 'insightful', 'relish', 'prodigy', 'genial', 'warmer', 'ecstatic', 'innovative', 'speedily', 'fruitful', 'undamaged', 'redeeming', 'blameless', 'beautifullly', 'staunchly', 'embolden', 'fortitude', 'reverence', 'faithful', 'interesting', 'luckiest', 'honest', 'heroize', 'brainiest', 'mesmerized', 'extraordinarily', 'promptly', 'nourish', 'helped', 'loving', 'exalt', 'radiance', 'satisfactory', 'unassailable', 'formidable', 'amazing', 'uplift', 'improve', 'supported', 'amicable', 'eminent', 'ambitious', 'simpler', 'fun', 'laud', 'coolest', 'frugal', 'rightful', 'amazed', 'ameliorate', 'excited', 'elite', 'keen', 'resounding', 'pleasurably', 'decisive', 'effortless', 'magnanimous', 'distinctive', 'unity', 'outperform', 'joy', 'equitable', 'peacefully', 'poised', 'enjoying', 'saintly', 'prudently', 'vibrant', 'well-managed', 'glistening', 'ambitiously', 'dawn', 'profound', 'merciful', 'adored', 'pamperedly', 'carefree', 'congenial', 'paramount', 'exemplary', 'satisfactorily', 'thrills', 'covenant', 'exonerate', 'exultation', 'aspire', 'sweeping', 'headway', 'revive', 'elegantly', 'complemented', 'restructured', 'logical', 'deference', 'refinement', 'useable', 'blossom', 'gratifying', 'remarkably', 'err-free', 'fresher', 'encouraging', 'glitz', 'encouragement', 'dominated', 'flourish', 'overtake', 'well-backlit', 'adulate', 'glisten', 'suitable', 'thrilling', 'entrust', 'fast-growing', 'passionately', 'roomier', 'clean', 'fastest', 'quiet', 'heroically', 'efficacious', 'favour', 'securely', 'promising', 'boundless', 'advocates', 'mighty', 'seasoned', 'conciliatory', 'maneuverable', 'prestigious', 'awesomeness', 'renowned', 'prosperity', 'delicate', 'eagerly', 'pardon', 'privilege', 'like', 'justly', 'heroine', 'supporter', 'safely', 'retractable', 'deserving', 'accomplishment', 'adulation', 'upgradeable', 'posh', 'top-notch', 'heartfelt', 'intrigue', 'afford', 'hotcakes', 'industrious', 'unabashed', 'nicest', 'authentic', 'free', 'topnotch', 'redemption', 'meaningful', 'effusion', 'godsend', 'captivating', 'venerate', 'elan', 'smooth', 'gaining', 'spellbind', 'best-known', 'positive', 'patriot', 'salutary', 'lucrative', 'zest', 'elation', 'pleased', 'enthusiastic', 'wisely', 'celebration', 'notably', 'detachable', 'well-intentioned', 'deservedly', 'loyal', 'ease', 'endorse', 'revolutionizes', 'foolproof', 'steadiest', 'record-setting', 'defeat', 'protection', 'blessing', 'low-risk', 'amusing', 'ftw', 'serene', 'optimism', 'substantive', 'succeeded', 'sumptuous', 'gorgeously', 'stunned', 'attractively', 'reformed', 'felicitous', 'outstrip', 'worthiness', 'rectify', 'energetic', 'rapt', 'kid-friendly', 'accessable', 'enthralled', 'enviable', 'snappy', 'tougher', 'integrated', 'miracles', 'proficiently', 'danken', 'impartiality', 'astonishing', 'ardor', 'assure', 'romantic', 'dextrous', 'problem-free', 'goodwill', 'radiant', 'obtainable', 'gratitude', 'bullish', 'festive', 'twinkly', 'chaste', 'awsome', 'dominate', 'simplest', 'tickle', 'pep', 'calming', 'grateful', 'togetherness', 'cute', 'gooood', 'prodigiously', 'excels', 'large-capacity', 'worked', 'surpass', 'straightforward', 'workable', 'eyecatch', 'convincingly', 'respite', 'complementary', 'sensible', 'pluses', 'capability', 'ebullient', 'heaven', 'problem-solver', 'hospitable', 'useful', 'helpful', 'vibrantly', 'cleanly', 'fans', 'edify', 'inspiration', 'euphorically', 'astutely', 'sane', 'excellant', 'vivacious', 'freedoms', 'sleek', 'rejuvenating', 'thankful', 'endorsement', 'indulgent', 'spotless', 'gain', 'righteous', 'enrich', 'excelled', 'steadfast', 'right', 'congratulate', 'comprehensive', 'stronger', 'peace', 'affirmation', 'supremacy', 'harmless', 'important', 'low-priced', 'electrify', 'precious', 'feasibly', 'unreal', 'easy-to-use', 'glad', 'refresh', 'exaltation', 'happy', 'sensibly', 'valiantly', 'calm', 'wowing', 'relent', 'convience', 'clearer', 'fragrant', 'enlightenment', 'innocuous', 'levity', 'elate', 'phenomenal', 'easiness', 'famous', 'unbound', 'ecstasies', 'pleasingly', 'charming', 'upbeat', 'kindliness', 'sporty', 'marvelous', 'exuberant', 'winner', 'considerate', 'serenity', 'exquisite', 'sophisticated', 'dexterously', 'reaffirm', 'preferring', 'awe', 'impress', 'upgraded', 'majestic', 'likable', 'plush', 'beneficiary', 'facilitate', 'heal', 'joyful', 'brightest', 'defeated', 'alluringly', 'humor', 'reachable', 'trivially', 'non-violent', 'exaltingly', 'dazzling', 'saintliness', 'productive', 'smoothly', 'scenic', 'glee', 'magnificently', 'cashback', 'refunded', 'hail', 'respect', 'adorer', 'interests', 'proves', 'cure', 'fervid', 'readily', 'complimentary', 'painlessly', 'groundbreaking', 'gladness', 'poetic', 'memorable', 'exalted', 'amply', 'freshest', 'hopeful', 'pepped', 'fantastic', 'encourage', 'well-made', 'refund', 'warmly', 'brilliances', 'influential', 'exalting', 'heartening', 'liking', 'adventuresome', 'enrapt', 'exceptional', 'super', 'smoothes', 'toughest', 'clears', 'flatteringly', 'poeticize', 'reasonable', 'tantalizing', 'slammin', 'ecstasy', 'excitement', 'superb', 'calmness', 'fairly', 'easing', 'god-given', 'comfort', 'tenacious', 'polished', 'affectionate', 'awesomely', 'acclaimed', 'led', 'versatile', 'suffice', 'miracle', 'wins', 'advanced', 'passionate', 'pleasant', 'cheer', 'breakthroughs', 'reliable', 'marvelled', 'blithe', 'fascination', 'fantastically', 'fondness', 'toll-free', 'exult', 'imaginative', 'properly', 'affluent', 'transparent', 'exellent', 'rightly', 'well', 'beauty', 'gloriously', 'charismatic', 'hot', 'mind-blowing', 'rich', 'eloquence', 'attractive', 'expansive', 'dotingly', 'frolic', 'adroit', 'simplifies', 'titillating', 'terrific', 'ardently', 'openly', 'decent', 'aspirations', 'gentle', 'destiny', 'resourceful', 'laudable', 'finest', 'accomplished', 'beautiful', 'intricate', 'autonomous', 'courteous', 'treasure', 'first-in-class', 'heros', 'fortuitous', 'rapturously', 'well-wishers', 'loved', 'unabashedly', 'dazzle', 'romanticize', 'valor', 'beautify', 'fervently', 'brotherly', 'better', 'inexpensive', 'patriotic', 'wonderfully', 'jubiliant', 'terrifically', 'remarkable', 'wowed', 'amaze', 'invaluable', 'honesty', 'gratifies', 'backbone', 'ennoble', 'hardier', 'steady', 'auspicious', 'advantages', 'all-around', 'merit', 'beutifully', 'poignant', 'winners', 'blissfully', 'strikingly', 'gem', 'benefactor', 'adulatory', 'divine', 'conveniently', 'heavenly', 'dead-on', 'rectification', 'winning', 'grand', 'unequivocally', 'ergonomical', 'majesty', 'celebratory', 'nice', 'bolster', 'leverage', 'courageously', 'unfazed', 'grandeur', 'proactive', 'authoritative', 'confident', 'astonishment', 'spectacularly', 'cost-effective', 'likes', 'impassioned', 'wonderous', 'coherent', 'exhilaratingly', 'surreal', 'earnestly', 'halcyon', 'mastery', 'jubilation', 'irreproachable', 'generous', 'luxuriate', 'faultless', 'indebted', 'lush', 'prudent', 'gains', 'energize', 'pride', 'bonus', 'recommended', 'readable', 'safe', 'boost', 'exhilaration', 'improving', 'homage', 'appreciate', 'sincerely', 'dependable', 'compassionate', 'assurance', 'rockstars', 'cozy', 'fervor', 'sturdier', 'affectation', 'admire', 'entertains', 'agreeableness', 'hooray', 'impressed', 'humane', 'blockbuster', 'understandable', 'reliably', 'entranced', 'conscientious', 'recomend', 'famed', 'profusion', 'master', 'accessible', 'celebrate', 'achievible', 'dignity', 'well-known', 'accomplish', 'prize', 'usable', 'well-mannered', 'noble', 'restructuring', 'prominence', 'wonder', 'glowing', 'yay', 'liked', 'honor', 'matchless', 'mesmerizes', 'restful', 'subsidize', 'permissible', 'inspire', 'instrumental', 'stately', 'neatly', 'gladly', 'vivid', 'enliven', 'irreplaceable', 'attune', 'portable', 'engaging', 'worth', 'cleverly', 'euphoric', 'amazement', 'leading', 'flutter', 'resplendent', 'grace', 'low-price', 'exceeding', 'proficient', 'inviolable', 'energy-saving', 'exultant', 'intimate', 'enchanting', 'unlimited', 'rightfully', 'prosper', 'mercifully', 'glamorous', 'cajole', 'empower', 'sprightly', 'adroitly', 'pamperedness', 'magnanimously', 'outstanding', 'sustainability', 'wealthy', 'immaculately', 'expertly', 'inviolate', 'sharper', 'self-sufficiency', 'stylish', 'cheapest', 'pamper', 'truthful', 'outperformed', 'jubilate', 'fancinating', 'stimulating', 'elegant', 'kindly', 'invigorate', 'timely', 'effective', 'delicious', 'undisputably', 'personages', 'profoundly', 'tidy', 'respectable', 'dependably', 'fancier', 'surmount', 'bountiful', 'revival', 'awestruck', 'brilliance', 'affinity', 'optimistic', 'welcome', 'tenaciously', 'bless', 'counter-attacks', 'elevate', 'productively', 'celebrated', 'loveliness', 'sturdy', 'healthy', 'famously', 'user-friendly', 'accomodative', 'exceed', 'exuberantly', 'noiseless', 'affirmative', 'brainy', 'triumph', 'relief', 'viewable', 'unbiased', 'easier', 'entice', 'preferes', 'tops', 'grin', 'admirable', 'crisper', 'immaculate', 'satisfies', 'ideal', 'risk-free', 'laudably', 'assuring', 'charmingly', 'spirited', 'nourishing', 'modern', 'sweet', 'glow', 'approval', 'rapturous', 'smart', 'soothingly', 'accurately', 'providence', 'afordable', 'upheld', 'zenith', 'humourous', 'soundness', 'precisely', 'booming', 'applaud', 'lean', 'invigorating', 'survival', 'breathtakingly', 'impeccably', 'wonders', 'courage', 'legendary', 'unquestionable', 'variety', 'exultingly', 'personalized', 'brand-new', 'awesome', 'cleanest', 'clear', 'tolerable', 'sweetheart', 'dauntless', 'amiable', 'lustrous', 'jubilantly', 'guiltless', 'wholesome', 'finer', 'endorsing', 'soulful', 'jaw-dropping', 'pleases', 'prefered', 'envy', 'masterpieces', 'profuse', 'altruistic', 'admiration', 'gratified', 'cheaper', 'appreciative', 'coherence', 'thrifty', 'achievements', 'beckon', 'glowingly', 'commodious', 'wonderously', 'luck', 'warmth', 'judicious', 'efficiently', 'faithfully', 'beneficial', 'oasis', 'delightfully', 'flashy', 'regally', 'fine-looking', 'doubtless', 'versatility', 'visionary', 'zippy', 'favored', 'motivated', 'extol', 'idol', 'enough', 'relaxed', 'enthusiasm', 'advocate', 'statuesque', 'recommendation', 'powerful', 'trophy', 'hug', 'jubilant', 'extraordinary', 'peps', 'gladden', 'ideally', 'lifesaver', 'compatible', 'remission', 'compact', 'irresistibly', 'commendable', 'renown', 'diplomatic', 'improved', 'advantage', 'enrapture', 'gainfully', 'cheerful', 'lead', 'hard-working', 'exceptionally', 'fascinatingly', 'slick', 'ebullience', 'enticing', 'superbly', 'lower-priced', 'effusive', 'brisk', 'firmer', 'morality', 'rational', 'ultra-crisp', 'titillatingly', 'cushy', 'veritable', 'bright', 'willing', 'inpressed', 'richness', 'woo', 'maturely', 'fervidly', 'ingeniously', 'simplify', 'comfortable', 'beneficially', 'overtakes', 'better-known', 'reforming', 'preeminent', 'dexterous', 'remunerate', 'succeed', 'peacekeepers', 'heroic', 'priceless', 'contrasty', 'reassure', 'gracious', 'keenness', 'liberate', 'patiently', 'hallowed', 'desirable', 'commendably', 'win', 'delectable', 'mercy', 'virtuously', 'alluring', 'fanfare', 'lyrical', 'enhancement', 'saver', 'harmoniously', 'meritorious', 'exceedingly', 'meticulously', 'recommendations', 'first-rate', 'delightfulness', 'enthrall', 'sagely', 'endear', 'first-class', 'goodly', 'gainful', 'masterful', 'eyecatching', 'overtaken', 'orderly', 'empathy', 'prolific', 'colorful', 'available', 'insightfully', 'merriness', 'hallmarks', 'recovery', 'shine', 'awarded', 'stunningly', 'admiringly', 'invincibility', 'fiery', 'noteworthy', 'impresses', 'excallent', 'intelligent', 'fortunately', 'outshone', 'dignified', 'prowess', 'feasible', 'prompt', 'solid', 'progress', 'avid', 'enhance', 'effusiveness', 'refined', 'sweetness', 'gained', 'well-rounded', 'commitment', 'playful', 'intimacy', 'affordably', 'divinely', 'appreciates', 'excellently', 'blissful', 'intuitive', 'instantly', 'snazzy', 'tenderly', 'diligently', 'dreamland', 'lavishly', 'renaissance', 'hallmark', 'refreshed', 'tranquility', 'catchy', 'idolized', 'dummy-proof', 'successfully', 'ecenomical', 'resourcefulness', 'irresistible', 'self-satisfaction', 'idealize', 'appealing', 'beckoning', 'empowerment', 'renewed', 'wieldy', 'richer', 'lionhearted', 'well-run', 'adjustable', 'confidence', 'skillful', 'upliftingly', 'lawful', 'daringly', 'supports', 'bonny', 'flexibility', 'idyllic', 'cleaner', 'fast', 'trust', 'elated', 'subsidizes', 'creative', 'fortune', 'reverent', 'roomy', 'flourishing', 'counter-attack', 'gratification', 'infallibly', 'trumpet', 'evenly', 'exceled', 'powerfully', 'stirringly', 'gush', 'fairness', 'wellbeing', 'mesmerizing', 'best-performing', 'indulgence', 'dedicated', 'gaiety', 'selective', 'handier', 'tingle', 'sufficed', 'cheery', 'inventive', 'humorously', 'magnificence', 'rejoicingly', 'capably', 'whoooa', 'wholeheartedly', 'staunch', 'gratifyingly', 'soft', 'masterpiece', 'unfettered', 'promise', 'stability', 'lover', 'reputation', 'spellbindingly', 'windfall', 'cohesive', 'faith', 'monumental', 'excel', 'suffices', 'pinnacle', 'rewardingly', 'wisdom', 'smiles', 'believeable', 'civilize', 'fortunate', 'passion', 'patient', 'concise', 'advocated', 'immense', 'well-bred', 'easiest', 'talented', 'intriguingly', 'excitedly', 'fidelity', 'lucidly', 'magic', 'revolutionary', 'lovably', 'exuberance', 'thrilled', 'worthy', 'benevolence', 'amicably', 'swiftness', 'triumphantly', 'unequivocal', 'tempt', 'magnificent', 'supurb', 'jolly', 'goood', 'impressive', 'desirous', 'felicitate', 'spellbinding', 'gentlest', 'enraptured', 'convincing', 'praise', 'individualized', 'enviably', 'verifiable', 'brilliantly', 'reasonably', 'sensation', 'dumbfounded', 'enchant', 'diligent', 'progressive', 'loves', 'invincible', 'helping', 'efficient', 'purify', 'goodness', 'success', 'award', 'quicker', 'piety', 'brighten', 'undaunted', 'amuse', 'nifty', 'exemplar', 'enviousness', 'worthwhile', 'favorite', 'empathize', 'knowledgeable', 'whooa', 'privileged', 'joyously', 'titillate', 'marvel', 'golden', 'gratefully', 'thoughtful', 'sparkle', 'tough', 'triumphant', 'flexible', 'ingenuously', 'benefits', 'instructive', 'sincere', 'stellar', 'enjoy', 'consistently', 'compliment', 'appreciated', 'pepping', 'polite', 'recommend', 'reconcile', 'illuminate', 'multi-purpose', 'approve', 'hands-down', 'nimble', 'invulnerable', 'standout', 'propitiously', 'victory', 'amicability', 'reaffirmation', 'cherish', 'engrossing', 'believable', 'enchanted', 'refine', 'fluent', 'lawfully', 'exceeds', 'innovation'}\n",
            "\n",
            "Negative words\n",
            "{'tyrant', 'repulsiveness', 'coercion', 'drained', 'downheartedly', 'smack', 'smelling', 'renunciation', 'contagious', 'pig', 'rigidness', 'drastically', 'rage', 'touts', 'usurp', 'hardheaded', 'occlude', 'cracked', 'head-aches', 'pitiful', 'unusually', 'lech', 'disaccord', 'snobbish', 'inhumanity', 'dissatisfy', 'fleeting', 'opinionated', 'ramshackle', 'knife', 'unpredictable', 'nepotism', 'afflict', 'apologists', 'outcry', 'bull****', 'drop-out', 'calumnious', 'unsophisticated', 'strictly', 'stampede', 'rumple', 'detest', 'unproving', 'hard-line', 'grumpily', 'ill-defined', 'cannibalize', 'gracelessly', 'failed', 'frantically', 'beastly', 'inarticulate', 'stifle', 'bunk', 'affront', 'immoderate', 'mystery', 'underestimate', 'hiliarious', 'asinininity', 'unreachable', 'violate', 'acerbate', 'bloated', 'avalanche', 'imposition', 'heck', 'retaliate', 'occluded', 'din', 'pinch', 'glaringly', 'lewd', 'little-known', 'offend', 'overthrow', 'thumbs-down', 'torturing', 'atrocity', 'impinge', 'ironic', 'selfinterested', 'displace', 'dislike', 'fatty', 'insubstantial', 'killed', 'pauper', 'dizzing', 'furiously', 'shun', 'helplessly', 'object', 'deplorably', 'draconian', 'jeopardy', 'lapsed', 'obscures', 'rotten', 'unseemly', 'lethargy', 'disapproval', 'annoyed', 'mishap', 'dreary', 'semi-retarded', 'slumping', 'uninsured', 'lame', 'misdirection', 'inept', 'back-woods', 'iniquity', 'grim', 'frenetic', 'indoctrinate', 'foe', 'objections', 'ignore', 'dismal', 'inconceivably', 'flare', 'regrets', 'sickening', 'garish', 'jaded', 'depressions', 'messed', 'unimaginable', 'scummy', 'nuisance', 'occluding', 'stumble', 'wanton', 'quarrelsome', 'forgetful', 'cave', 'gimmicks', 'fatcat', 'dissidents', 'domineering', 'dumb', 'bruised', 'inconsequently', 'vexation', 'impolite', 'infections', 'hum', 'dumped', 'overshadow', 'dilapidated', 'stern', 'dissemble', 'traumatized', 'balk', 'hustler', 'molest', 'fractiously', 'worst', 'delayed', 'betrayal', 'squabbling', 'huckster', 'suspect', 'emphatically', 'lonely', 'insulting', 'lull', 'unaccessible', 'deride', 'superstition', 'defiler', 'dragged', 'hypocritically', 'disdainful', 'crashes', 'dissatisfactory', 'lascivious', 'loathly', 'puny', 'god-awful', 'stressful', 'premeditated', 'desolation', 'disapointment', 'smash', 'volatile', 'manipulative', 'overbearing', 'backbite', 'straggle', 'unnatural', 'complex', 'incoherent', 'time-consuming', 'excessively', 'flicering', 'prison', 'manipulators', 'creeps', 'superficial', 'peeved', 'unspecified', 'depressingly', 'lapses', 'phobic', 'scratch', 'disoriented', 'displeasure', 'misinform', 'wound', 'impose', 'backbiting', 'gripe', 'obsessive', 'upsettingly', 'lanky', 'misbegotten', 'rhapsodize', 'fool', 'rattled', 'remorsefully', 'confused', 'crept', 'derogatory', 'encroach', 'antiquated', 'hassles', 'harrow', 'inconsolably', 'pickets', 'unappealing', 'exploitation', 'stiff', 'maliciously', 'diabolic', 'pry', 'concession', 'incongruous', 'crashed', 'crack', 'rejects', 'notorious', 'jarring', 'cataclysmal', 'dissention', 'calamity', 'fanciful', 'pollute', 'jaundiced', 'grievous', 'lazy', 'shiver', 'worrying', 'attacks', 'misalign', 'simplistic', 'bugging', 'uneasy', 'sabotage', 'abrade', 'onerous', 'bloodshed', 'ill-advised', 'misreading', 'lugubrious', 'monstrously', 'shark', 'scandalous', 'lecher', 'emasculate', 'inglorious', 'indiscernible', 'fatuity', 'sucked', 'threesome', 'capitulate', 'acridness', 'noxious', 'unexpected', 'wrinkled', 'harm', 'animosity', 'exhaustion', 'distraughtly', 'doomed', 'pillage', 'doom', 'protracted', 'conflicting', 'ulterior', 'irresolvable', 'sting', 'superficially', 'stinks', 'punitive', 'confusion', 'heartless', 'accusing', 'incorrigibly', 'vibrates', 'disappoint', 'direness', 'meager', 'critical', 'spoilages', 'stinging', 'battered', 'offenses', 'reckless', 'gross', 'exorbitant', 'resigned', 'smudged', 'austere', 'laughable', 'dangerous', 'drunkard', 'suspicions', 'revert', 'ambush', 'obscure', 'abominate', 'straining', 'paupers', 'invidiously', 'heartbreaking', 'inexcusable', 'laid-off', 'cuss', 'peculiarly', 'peevishly', 'indecisive', 'overstate', 'punish', 'suspicion', 'dings', 'malady', 'lacked', 'coarse', 'stigmatize', 'fluster', 'loses', 'loser', 'stringent', 'scandals', 'unacceptably', 'pander', 'intefere', 'appalling', 'futile', 'misstatement', 'falter', 'fatcats', 'solicitude', 'bothered', 'bullshyt', 'incomparably', 'hapless', 'manipulate', 'equivocal', 'utterly', 'omit', 'quarrellous', 'unproductive', 'abomination', 'incapable', 'entangle', 'deprave', 'overwhelmed', 'prevaricate', 'sloppy', 'catastrophe', 'murky', 'doubt', 'ridiculous', 'blackmail', 'prohibitive', 'dissonant', 'daze', 'destructive', 'shatter', 'unprove', 'self-criticism', 'cramp', 'trashy', 'farfetched', 'grouse', 'venom', 'delaying', 'irresponsible', 'contort', 'indignant', 'cartoonish', 'defile', 'ineffectually', 'pompous', 'puzzled', 'stormy', 'spank', 'calamitous', 'oppositions', 'harbors', 'oversimplified', 'criticism', 'faint', 'peevish', 'tenuous', 'impotent', 'limp', 'rankle', 'bothers', 'alarmed', 'bigotry', 'cheerless', 'denunciations', 'maliciousness', 'outrages', 'darkened', 'pestilent', 'gangster', 'enmity', 'oversimplification', 'baseless', 'ineffectual', 'limitation', 'snags', 'unfamiliar', 'sardonic', 'despotic', 'notoriously', 'recalcitrant', 'dissonantly', 'contravene', 'swindle', 'impersonal', 'meddle', 'farcical', 'shortcoming', 'sorrow', 'depraved', 'extraneous', 'death', 'bland', 'flat-out', 'sluggish', 'disillusions', 'inefficiently', 'stun', 'violently', 'writhe', 'exile', 'sugarcoated', 'frightful', 'massacres', 'infest', 'harried', 'anti-us', 'annihilation', 'unconstitutional', 'hideousness', 'perverted', 'mercilessly', 'retard', 'cumbersome', 'incoherently', 'resentful', 'mournfully', 'blindingly', 'impulsive', 'inimical', 'languorously', 'insincerity', 'unable', 'repress', 'despondency', 'lied', 'sty', 'untimely', 'imaginary', 'dirt', 'insufferably', 'wheedle', 'venomous', 'baffling', 'nebulous', 'rumours', 'timid', 'testy', 'warped', 'maltreatment', 'misses', 'trample', 'tumultuous', 'gruff', 'imminence', 'polution', 'disquieting', 'alienation', 'carp', 'insignificantly', 'unclean', 'uncomfortably', 'warned', 'fallacious', 'adulteration', 'discourteous', 'overrun', 'smelled', 'malevolence', 'spurious', 'pointlessly', 'uneasily', 'forbidding', 'debilitate', 'chatterbox', 'pitiless', 'oddest', 'ignominiously', 'neglect', 'maddeningly', 'conceded', 'intractable', 'asunder', 'disorganized', 'melodramatic', 'distraughtness', 'irritation', 'fractious', 'hamper', 'incitement', 'wildly', 'taboo', 'figurehead', 'undependable', 'terror', 'freakishly', 'cancerous', 'disgustfully', 'blunders', 'bravado', 'frustratingly', 'deluge', 'inconsistence', 'exploit', 'betraying', 'timidity', 'sermonize', 'indecent', 'exasperation', 'mourner', 'burdensome', 'discontentedly', 'condemned', 'proprietary', 'self-interest', 'overlook', 'overreach', 'smuttiest', 'imprudence', 'penalty', 'taunt', 'terribly', 'accost', 'hinder', 'drips', 'sever', 'unconfirmed', 'demoralize', 'foolish', 'unforgiving', 'vomited', 'limits', 'invisible', 'abrupt', 'contrariness', 'blemish', 'inaccuracy', 'lack', 'decry', 'impure', 'poverty', 'smells', 'undercut', 'underdog', 'capricious', 'detracting', 'stupify', 'evil', 'complicit', 'galling', 'ghastly', 'guilty', 'mispronounces', 'flickers', 'scandalize', 'died', 'insinuating', 'recklessness', 'fascism', 'biting', 'posturing', 'shipwreck', 'nastily', 'ungovernable', 'precarious', 'horrifying', 'encroachment', 'disobey', 'wane', 'worrisome', 'besiege', 'deterrent', 'furious', 'invective', 'indecisively', 'blurry', 'fatal', 'villify', 'bitingly', 'cruelest', 'vomiting', 'moronic', 'irreformable', 'overrated', 'embroilment', 'fictional', 'hooligan', 'resurgent', 'dullard', 'goon', 'grudge', 'interruption', 'loophole', 'accusations', 'cataclysmic', 'temptation', 'hestitant', 'weaknesses', 'draconic', 'floundering', 'discountenance', 'recklessly', 'strife', 'vent', 'aggravate', 'dissapointed', 'radical', 'ruthless', 'hampered', 'sadness', 'intrude', 'dissappointed', 'adamantly', 'hideously', 'inaccuracies', 'slower', 'unskilled', 'frenzy', 'superstitious', 'zombie', 'challenging', 'denigrate', 'overwhelms', 'enemies', 'impasse', 'seedy', 'morbidly', 'tacky', 'negligent', 'misleading', 'pathetically', 'undefined', 'exagerates', 'ferociously', 'slogging', 'loner', 'sag', 'displaced', 'dragging', 'immoderately', 'terrible', 'hell', 'ill-tempered', 'swamped', 'clumsy', 'flakey', 'frighteningly', 'assail', 'blah', 'mockery', 'rival', 'fallen', 'hothouse', 'oppose', 'snare', 'haunt', 'mistrustful', 'debilitating', 'disturbance', 'uncouth', 'haggle', 'rantingly', 'deviate', 'freaking', 'timidly', 'butchery', 'betrayer', 'annoyingly', 'overthrows', 'unwillingness', 'overstated', 'evasive', 'infiltrators', 'traumatize', 'paranoid', 'disagreement', 'stagnant', 'weird', 'hatefully', 'ruin', 'antagonist', 'archaic', 'contrive', 'sap', 'infuriate', 'painfull', 'pretend', 'draining', 'quarrellously', 'disadvantaged', 'disapointing', 'fidgety', 'outrageously', 'shaky', 'culpable', 'jeeringly', 'losing', 'mistified', 'wallow', 'fearfully', 'squeals', 'forsaken', 'resentment', 'liable', 'pandering', 'thrash', 'opponent', 'knave', 'brashly', 'demonizes', 'mess', 'disparaging', 'freak', 'kooky', 'buzzing', 'embarrassment', 'lacking', 'woefully', 'frets', 'hegemonistic', 'contemptible', 'disheartening', 'hurted', 'inundated', 'raped', 'snappish', 'volatility', 'needy', 'haughty', 'negation', 'objectionable', 'crowdedness', 'egregiously', 'damages', 'two-faces', 'craziness', 'unusably', 'snappishly', 'unspeakable', 'unspeakablely', 'perplexing', 'squabble', 'fretful', 'excruciating', 'castrated', 'addict', 'bungler', 'grievously', 'wounds', 'unethical', 'outbreak', 'stubbornly', 'curse', 'parody', 'miscreants', 'cringe', 'ill-used', 'disrespect', 'counter-productive', 'despise', 'ambivalent', 'deviousness', 'backaches', 'divisively', 'extort', 'laggy', 'insincerely', 'bleakness', 'despondently', 'frightfully', 'hardliner', 'miserably', 'disappointingly', 'hatefulness', 'nervousness', 'pedantic', 'smouldering', 'tentatively', 'declining', 'crashing', 'slogs', 'mistaken', 'disagreed', 'outrageous', 'aweful', 'overloaded', 'bored', 'doubtfully', 'beggar', 'restriction', 'unintelligible', 'treacherously', 'baffled', 'sidetracked', 'addicting', 'absence', 'halfhearted', 'conspirator', 'exhaust', 'traitorous', 'revenge', 'childish', 'dent', 'contaminating', 'apologist', 'deceitful', 'misbehavior', 'so-cal', 'unsettled', 'disdained', 'high-priced', 'overwhelm', 'naughty', 'prik', 'tricky', 'tantrum', 'unjustifiably', 'confront', 'insincere', 'vehement', 'deceptive', 'f**k', 'upbraid', 'dizzingly', 'costlier', 'unjustifiable', 'asperse', 'renounce', 'inflammed', 'questionable', 'incompetently', 'flout', 'caustic', 'dubitable', 'awfulness', 'fudge', 'indigent', 'wrong', 'restrictive', 'distortion', 'drains', 'latency', 'issues', 'fearful', 'revoltingly', 'stingy', 'dissuade', 'deter', 'intoxicate', 'carelessness', 'recourses', 'shamelessly', 'zapped', 'subordinate', 'dishonestly', 'hardship', 'demonizing', 'fundamentalism', 'aggressive', 'idle', 'desecrate', 'unsatisfactory', 'pity', 'yawn', 'obscured', 'aground', 'burn', 'blundering', 'left-leaning', 'babble', 'long-winded', 'forbidden', 'abused', 'rude', 'scary', 'tormented', 'hissing', 'insane', 'election-rigger', 'bully', 'exhorbitant', 'discompose', 'commotion', 'imminently', 'over-hyped', 'aggravation', 'bragger', 'discombobulate', 'greed', 'faults', 'slow', 'lawbreaker', 'persecute', 'uncooperative', 'frustrating', 'motionless', 'contortions', 'suffer', 'doggedly', 'frenzied', 'tarnished', 'grouchy', 'prick', 'vainly', 'disinterested', 'bruise', 'envious', 'harshly', 'savaged', 'lacks', 'falsify', 'complacent', 'marginal', 'involuntary', 'sweaty', 'dangerousness', 'refused', 'sore', 'anti-', 'struggles', 'weakness', 'abusive', 'assult', 'commonplace', 'cranky', 'deadbeat', 'dope', 'decrepitude', 'muddle', 'threat', 'unnervingly', 'mourn', 'humiliate', 'crumbling', 'annoying', 'pillory', 'belie', 'drag', 'endanger', 'inferior', 'tumble', 'brutalizing', 'contamination', 'famished', 'miscalculate', 'unleash', 'unsettle', 'graft', 'scratches', 'vindictiveness', 'extremism', 'incompetent', 'worse', 'underpaid', 'hell-bent', 'undesirable', 'grisly', 'apathetic', 'disquietude', 'indiscreet', 'judders', 'pratfall', 'stress', 'wrinkle', 'aghast', 'smudges', 'immorality', 'boastful', 'flaw', 'fume', 'harms', 'blister', 'mocking', 'miss', 'dehumanize', 'anti-semites', 'inadverent', 'smudging', 'brat', 'smuttier', 'underlings', 'pan', 'enviously', 'unfortunate', 'unexpectedly', 'liar', 'ingrate', 'jealousness', 'forebodingly', 'hassled', 'conservative', 'self-coup', 'squash', 'immoral', 'swipe', 'scolding', 'scam', 'trashed', 'ill-mannered', 'rubbish', 'delirium', 'massacre', 'inaudible', 'toughness', 'refuting', 'abnormal', 'unhappy', 'painfully', 'deteriorating', 'smudge', 'teasingly', 'contradict', 'inanely', 'toll', 'dishonorable', 'unnecessary', 'criticized', 'bewildering', 'bedlamite', 'demoralizingly', 'overheat', 'epidemic', 'sacrificed', 'devastate', 'downgrade', 'deceitfully', 'stupid', 'forfeit', 'fruitlessly', 'illness', 'illusions', 'incongruously', 'mulish', 'disruption', 'unlamentably', 'ho-hum', 'denial', 'leer', 'perfidity', 'problem', 'broke', 'barbarously', 'fraud', 'infamous', 'cuplrit', 'rift', 'twists', 'disbeliever', 'reticent', 'bitchy', 'revolt', 'dunce', 'overpower', 'pleas', 'tarnish', 'incorrigible', 'fraught', 'bedlam', 'unavoidably', 'fissures', 'drunk', 'exasperatingly', 'full-blown', 'gall', 'reprove', 'snarl', 'indiscriminating', 'belittle', 'bumping', 'overacted', 'sober', 'paucity', 'infection', 'disliking', 'clogged', 'midget', 'mislead', 'plasticky', 'breakdown', 'snob', 'overbearingly', 'spoon-fed', 'junky', 'instable', 'sneaky', 'heavy-handed', 'restlessness', 'foolhardy', 'cheated', 'hindrance', 'lackadaisical', 'contemptuously', 'petrified', 'spade', 'starvation', 'scrambles', 'argumentative', 'litigious', 'prejudices', 'improperly', 'pricier', 'hang', 'scandalized', 'discourage', 'killjoy', 'hung', 'jealousy', 'fat-cats', 'unlawfully', 'woeful', 'arduously', 'relentless', 'emergency', 'extermination', 'kills', 'puzzlement', 'adulterated', 'less-developed', 'scarred', 'sloooow', 'dejection', 'far-fetched', 'despondent', 'madman', 'malevolent', 'demise', 'bleed', 'disown', 'misunderstood', 'strident', 'dumbfound', 'rejecting', 'sufferers', 'instability', 'tangle', 'nauseates', 'vile', 'goad', 'skeptical', 'monotonous', 'matte', 'belligerent', 'accidental', 'disconcerting', 'ironically', 'harsh', 'pale', 'slooow', 'incite', 'avenge', 'mudslinging', 'bashful', 'berserk', 'junk', 'confounding', 'sly', 'desiccate', 'taunting', 'clash', 'inadequately', 'scornfully', 'malign', 'slanderous', 'manipulation', 'stew', 'unemployed', 'rhetoric', 'hysteria', 'bent', 'inflict', 'disgust', 'sully', 'clamor', 'goof', 'incorrect', 'mendacious', 'pretence', 'distasteful', 'costly', 'aggravating', 'doddering', 'declaim', 'disquietingly', 'disrespectable', 'calumny', 'dauntingly', 'nettlesome', 'dense', 'detraction', 'mysteriously', 'slashing', 'stumped', 'tyrannically', 'irking', 'dead', 'scrap', 'top-heavy', 'betray', 'drippy', 'maledict', 'mocked', 'tense', 'repulsed', 'unviewable', 'unyielding', 'irretating', 'exorbitantly', 'cruelties', 'inadvisable', 'restrict', 'uncreative', 'dirtbag', 'emaciated', 'selfishness', 'unsteadily', 'impudently', 'sinfully', 'injury', 'rebellious', 'crude', 'tortuous', 'coercive', 'dissident', 'viciousness', 'doubts', 'prejudge', 'slur', 'insultingly', 'radicalization', 'devilment', 'freezing', 'ominously', 'droops', 'idiocy', 'mocks', 'resignation', 'sneeringly', 'audaciousness', 'timidness', 'idiotically', 'mangling', 'rants', 'fiasco', 'sue', 'scared', 'delusions', 'criticizing', 'coerce', 'fatigued', 'rusty', 'spook', 'snobby', 'slap', 'incognizant', 'disintegrate', 'refute', 'tauntingly', 'ugliest', 'undone', 'dazed', 'scant', 'unsteadiness', 'chastisement', 'tawdry', 'defects', 'inequitable', 'inopportune', 'insensitivity', 'fatuously', 'shock', 'decayed', 'disconsolate', 'cheapen', 'scoundrel', 'stall', 'warp', 'hoard', 'commiserate', 'farcical-yet-provocative', 'mangled', 'oddity', 'stale', 'tainted', 'stealing', 'struggling', 'violent', 'scandel', 'spite', 'unpleasantries', 'diffidence', 'waste', 'traitor', 'mendacity', 'riled', 'depressing', 'hardhearted', 'fury', 'hysteric', 'incendiary', 'acerbically', 'discontented', 'inconsequent', 'last-ditch', 'meaningless', 'nefarious', 'overturn', 'audaciously', 'bid-rigging', 'randomly', 'loathsome', 'unlikely', 'bulkier', 'misfortune', 'degeneration', 'thwart', 'over-balanced', 'wimpy', 'impudence', 'puppet', 'worry', 'virulence', 'chaotic', 'anomalous', 'evildoer', 'inflame', 'disprove', 'disorder', 'falling', 'nightmare', 'petrify', 'snobish', 'tangled', 'deploring', 'mournful', 'acridly', 'dinky', 'indulge', 'anarchy', 'menacingly', 'discontinuity', 'embarrassingly', 'confrontational', 'acrimony', 'gravely', 'grainy', 'debts', 'dissolute', 'ignoble', 'mist', 'blasted', 'daunt', 'radicals', 'reprehensive', 'unlawfulness', 'ill-conceived', 'over-valuation', 'blurred', 'heretical', 'tenderness', 'extremist', 'frantic', 'stingingly', 'disturbing', 'crook', 'detested', 'harmful', 'inexcusably', 'self-destructive', 'delays', 'bother', 'disavowal', 'creaks', 'disagreeably', 'disillusioned', 'outcast', 'recessionary', 'handicapped', 'leech', 'besmirch', 'hype', 'terribleness', 'ironies', 'flawed', 'anxiousness', 'pokey', 'spews', 'bewail', 'gaudy', 'misgiving', 'indignation', 'inconsiderate', 'tangles', 'tanked', 'lecherous', 'tardy', 'hypocrite', 'crooked', 'fiend', 'shameless', 'involuntarily', 'hallucinate', 'fatally', 'vindictive', 'indecorum', 'imposing', 'repugnant', 'rhetorical', 'moody', 'imperious', 'dumps', 'narrower', 'flagrantly', 'fears', 'combative', 'unreliability', 'asininely', 'jittery', 'seriousness', 'overemphasize', 'impossible', 'forlorn', 'outrage', 'misfit', 'sneer', 'hurt', 'apprehension', 'screwy', 'deject', 'inattentive', 'indecision', 'calumniate', 'accursed', 'lagging', 'dissolution', 'direly', 'flares', 'funnily', 'disable', 'blurs', 'ill-sorted', 'molestation', 'needlessly', 'screech', 'squealing', 'damned', 'cowardly', 'inflammatory', 'ignorance', 'irragularity', 'unfaithful', 'nettle', 'dies', 'troublesomely', 'foul', 'gainsayer', 'slumpping', 'abominable', 'caricature', 'browbeat', 'martyrdom', 'corrupt', 'blinding', 'broken', 'submissive', 'inefficacious', 'discourteously', 'crippling', 'indistinguishable', 'messy', 'frazzle', 'clueless', 'severe', 'vulgar', 'threats', 'importunate', 'filthy', 'delusion', 'ingratitude', 'scariest', 'unresolved', 'downside', 'risky', 'adamant', 'inconsequential', 'demolisher', 'vague', 'unlawful', 'nosey', 'clamorous', 'inappropriate', 'fastuous', 'obliterate', 'overzelous', 'defensive', 'jutters', 'taxing', 'invader', 'refutation', 'water-down', 'obscene', 'damn', 'fret', 'dreadful', 'lament', 'growl', 'dents', 'entrapment', 'illegal', 'long-time', 'poisonous', 'stressfully', 'niggles', 'traitorously', 'villainously', 'symptoms', 'provocation', 'stains', 'antipathy', 'killer', 'scapegoat', 'aspersions', 'breakup', 'fateful', 'erodes', 'hysterical', 'instigator', 'motley', 'rascal', 'uncollectible', 'unprofitable', 'repressive', 'divisive', 'stupor', 'overpayed', 'perfidious', 'hardball', 'menacing', 'omission', 'nitpicking', 'unipolar', 'madder', 'destabilisation', 'undignified', 'famine', 'expire', 'grumble', 'villianous', 'bad', 'calumniation', 'smoulder', 'suspiciously', 'zap', 'lapse', 'bashing', 'acerbic', 'dictatorial', 'lovelorn', 'cruel', 'savagery', 'hateful', 'troubled', 'womanizer', 'obtrusive', 'condemns', 'disputable', 'belligerently', 'destroyer', 'irreparable', 'innuendo', 'smelly', 'ultra-hardline', 'tin-y', 'invasive', 'clunky', 'delay', 'passiveness', 'irrecoverableness', 'faltered', 'inadvisably', 'gloatingly', 'flounder', 'mistakenly', 'remorse', 'solemn', 'unuseably', 'maniacal', 'weary', 'anxieties', 'negate', 'funky', 'terror-genic', 'delude', 'blame', 'dying', 'mawkishly', 'demonic', 'isolation', 'throb', 'detracts', 'amputate', 'deign', 'downhill', 'sulk', 'wail', 'troublesome', 'profane', 'burden', 'demonize', 'limited', 'calamities', 'cocky', 'incomprehensible', 'overweight', 'discomfititure', 'unprepared', 'adulterate', 'scathing', 'sinister', 'disobedient', 'distrusting', 'inveigle', 'dusty', 'indecently', 'prideful', 'exclusion', 'grate', 'anxiety', 'loathsomely', 'plaything', 'arrogantly', 'dragoon', 'finagle', 'corrupts', 'cracks', 'fever', 'mystify', 'obstinately', 'fuck', 'hazy', 'cynicism', 'spitefulness', 'd*mn', 'difficulty', 'malcontented', 'orphan', 'sleazy', 'shoddy', 'uproar', 'delusional', 'lechery', 'bugs', 'aggressor', 'frigid', 'scorchingly', 'warlike', 'erroneously', 'irrationality', 'mysterious', 'strut', 'allergic', 'loveless', 'shallow', 'hesitant', 'sloppily', 'disgraced', 'ridicules', 'perturbed', 'spookier', 'distastefully', 'kook', 'ill-treatment', 'admonishingly', 'hating', 'immature', 'fiendish', 'jeers', 'strained', 'ugh', 'unauthentic', 'fuss', 'mismanage', 'incense', 'lawbreaking', 'upseting', 'scuff', 'enfeeble', 'diatribe', 'offence', 'pains', 'harden', 'flirty', 'discomfort', 'run-down', 'redundancy', 'unorthodox', 'upsets', 'error', 'furor', 'beset', 'scornful', 'villianously', 'negative', 'grieving', 'douchebag', 'tiring', 'cry', 'doubtful', 'queer', 'infirm', 'viciously', 'contradictory', 'stubbornness', 'shrivel', 'joker', 'mangle', 'unknown', 'peeled', 'usurper', 'slowed', 'bombard', 'grudges', 'flaunt', 'egotism', 'contend', 'feint', 'provocative', 'leery', 'deploringly', 'despised', 'retards', 'obstacle', 'unsupportive', 'braggart', 'haughtily', 'impertinent', 'dearth', 'entrap', 'rumbling', 'insolvent', 'irony', 'ruins', 'insensitively', 'uneventful', 'pessimism', 'waning', 'debaucher', 'hatred', 'dishonorablely', 'insinuate', 'mangles', 'perturb', 'payback', 'snarky', 'gibe', 'amiss', 'exacerbate', 'rampant', 'madness', 'deform', 'leaking', 'mania', 'tingled', 'wretchedly', 'feeble', 'ludicrous', 'bs', 'fallacies', 'hubris', 'repel', 'scare', 'sneakily', 'messing', 'chastise', 'condescension', 'harpy', 'inactive', 'clouding', 'chaff', 'insurmountably', 'intermittent', 'undermining', 'disconsolately', 'hiss', 'fucking', 'inconveniently', 'irrepressible', 'superfluous', 'mordant', 'repetitive', 'desperation', 'shrug', 'infernal', 'travesties', 'doomsday', 'disparagingly', 'overbalanced', 'paltry', 'disservice', 'deception', 'grudging', 'deteriorate', 'inhibit', 'bafflement', 'invalidity', 'over-priced', 'escapade', 'cannibal', 'dissent', 'blotchy', 'discord', 'cruelly', 'panicking', 'lone', 'ambiguous', 'disunity', 'trivialize', 'uneven', 'indignity', 'unorthodoxy', 'critic', 'toxic', 'filth', 'inexpertly', 'satirical', 'fake', 'illusory', 'thirst', 'tragically', 'reprehension', 'vestiges', 'troubling', 'bickering', 'dilemma', 'adversity', 'hostilities', 'partisans', 'scoff', 'slowwww', 'iniquitous', 'tingling', 'wince', 'venomously', 'sneak', 'irksomeness', 'unnerve', 'creaking', 'atrocities', 'depravedly', 'inoperable', 'numb', 'saggy', 'breaking', 'glut', 'grumpish', 'indeterminable', 'insanely', 'misgivings', 'stuttering', 'racy', 'grievance', 'mischief', 'sorely', 'dismayed', 'unproven', 'shrill', 'alienate', 'unfeeling', 'pimple', 'offensively', 'fat-cat', 'uninformed', 'uproarous', 'oppressiveness', 'muscle-flexing', 'staid', 'oppressors', 'destitution', 'contradiction', 'over-awe', 'disinclination', 'showdown', 'fussy', 'wrest', 'bereavement', 'lunaticism', 'oversight', 'naively', 'drastic', 'disloyalty', 'discontent', 'unneeded', 'broken-hearted', 'flighty', 'poisonously', 'tyranny', 'unscrupulously', 'damper', 'rue', 'menial', 'corrupted', 'regret', 'shirk', 'irritations', 'trick', 'sanctimonious', 'fawningly', 'wrangle', 'contaminated', 'wretch', 'boil', 'pugnacious', 'emphatic', 'undersized', 'shortsighted', 'mislike', 'confessions', 'impulsively', 'recession', 'inane', 'spewed', 'sh*t', 'susceptible', 'neurotic', 'acrimonious', 'occludes', 'scandels', 'chintzy', 'vibrated', 'irks', 'appallingly', 'trickery', 'concessions', 'cripples', 'disabled', 'set-up', 'unaffordable', 'wreck', 'skittish', 'impetuous', 'dispensable', 'spiteful', 'mawkish', 'merciless', 'scream', 'inexperience', 'lamentably', 'haggard', 'bait', 'carnage', 'insatiable', 'prickles', 'rusts', 'prohibit', 'maladjustment', 'ludicrously', 'kill', 'fatique', 'jabber', 'detrimental', 'suffered', 'trivial', 'debatable', 'hopeless', 'craftly', 'injurious', 'deluded', 'blaspheme', 'rebuke', 'murderer', 'dismissive', 'unbearable', 'facetiously', 'insignificance', 'buckle', 'laconic', 'stymied', 'unbelievably', 'regressive', 'implode', 'depression', 'impetuously', 'negatives', 'letch', 'stresses', 'tetchily', 'fruitless', 'beleaguer', 'deficiency', 'hopelessness', 'stuffy', 'retreated', 'uproarously', 'unfulfilled', 'dissing', 'clogs', 'exhort', 'overstates', 'overwhelming', 'undermine', 'diss', 'undercuts', 'scramble', 'longingly', 'frictions', 'languor', 'enflame', 'insolently', 'despairingly', 'paradoxically', 'repugnance', 'brutalize', 'unsettlingly', 'disapproving', 'immodest', 'setbacks', 'hollow', 'vilify', 'effrontery', 'headache', 'unhappiness', 'mistakes', 'inconsequentially', 'unrelentingly', 'dissed', 'dispirited', 'spoil', 'woe', 'importune', 'plunderer', 'abrasive', 'nagging', 'deformed', 'insolent', 'gritty', 'prickle', 'illiterate', 'compulsive', 'vindictively', 'degrading', 'defiant', 'unnoticed', 'shocking', 'lurch', 'cold', 'unreliable', 'bemoan', 'misunderstand', 'foolishness', 'insupportably', 'oblique', 'disastrous', 'disorient', 'revengeful', 'hedge', 'die', 'knock', 'unobserved', 'watered-down', 'cloudy', 'befoul', 'low-rated', 'shockingly', 'banishment', 'hostile', 'crumble', 'dwindling', 'picket', 'consternation', 'disapointed', 'shit', 'shrouded', 'licentiously', 'callous', 'weaken', '2-faces', 'irregularity', 'weakening', 'hurts', 'scarcely', 'admonish', 'odor', 'outburst', 'hypocrisy', 'siege', 'suck', 'calumnies', 'dented', 'smell', 'lumpy', 'disapprobation', 'concerns', 'mispronounce', 'unease', 'ostracize', 'alienated', 'disagrees', 'misjudgment', 'lemon', 'irrationals', 'forlornly', 'phobia', 'idiocies', 'inefficient', 'evade', 'bastard', 'frightening', 'second-tier', 'crippled', 'dimmer', 'denunciation', 'rust', 'scrambled', 'dissonance', 'ill-formed', 'blow', 'pain', 'absurdly', 'crooks', 'raping', 'sketchy', 'misaligned', 'thoughtless', 'jolt', 'passe', 'dissembler', 'morbid', 'apocalyptic', 'complaints', 'procrastination', 'blandish', 'blind', 'ripoff', 'disaffirm', 'wobbles', 'disillusion', 'irreconcilable', 'inculcate', 'incompatability', 'unmoved', 'gaff', 'abuse', 'rampage', 'war-like', 'bullshit', 'perplex', 'erratic', 'confusing', 'flairs', 'dire', 'losses', 'shirker', 'gloomy', 'implicate', 'galls', 'jealously', 'arbitrary', 'itchy', 'provoke', 'spendy', 'subservience', 'ferocity', 'vex', 'rejection', 'inundate', 'unsuccessfully', 'transgress', 'antagonize', 'felon', 'frazzled', 'glum', 'idiotic', 'ill-natured', 'shroud', 'bloody', 'ached', 'squander', 'aversion', 'stunt', 'ungrateful', 'congested', 'grotesque', 'misunderstanding', 'pretentiously', 'audacious', 'dishearten', 'refuse', 'mortifying', 'traumatic', 'bastards', 'blunder', 'distracting', 'irascible', 'reprimand', 'servitude', 'dismaying', 'weep', 'subversion', 'scaly', 'sloww', 'frenetically', 'desiccated', 'inefficiency', 'embroiled', 'rumors', 'bug', 'sarcastically', 'irk', 'troublingly', 'listless', 'immorally', 'slowly', 'inconvenience', 'repulsing', 'bemoaning', 'awful', 'enervate', 'gimmicky', 'hoodwink', 'unusable', 'bitter', 'impropriety', 'crime', 'odder', 'phony', 'worries', 'impediment', 'bleakly', 'futilely', 'crummy', 'unrealistic', 'choke', 'degenerate', 'fascist', 'gutless', 'brashness', 'irreplacible', 'lurk', 'mistrustfully', 'foulness', 'testily', 'mists', 'senile', 'womanizing', 'malcontent', 'dull', 'plebeian', 'forgetfully', 'spotty', 'covetous', 'disavow', 'dreadfulness', 'excuse', 'interfere', 'abominably', 'shunned', 'excessive', 'difficult', 'stricken', 'creepy', 'grievances', 'hopelessly', 'glib', 'sugar-coat', 'unaccustomed', 'vomits', 'isolated', 'bull----', 'one-sided', 'aggrieve', 'sedentary', 'depress', 'nastiness', 'inessential', 'thumb-down', 'curses', 'retreat', 'backache', 'bomb', 'embroil', 'craps', 'unimaginably', 'heartbreakingly', 'incompliant', 'inhospitality', 'irrelevance', 'extravagantly', 'louder', 'melancholy', 'ruthlessly', 'conspicuous', 'primitive', 'spoils', 'banal', 'aggrieved', 'chafe', 'picketing', 'sunken', 'unimportant', 'pertinacity', 'tragic', 'warning', 'exaggerate', 'impossiblity', 'biases', 'impoverish', 'impunity', 'travesty', 'chronic', 'funny', 'indeterminably', 'unwarranted', 'concens', 'villains', 'smug', 'inflammation', 'dispute', 'macabre', 'swagger', 'incautious', 'boisterous', 'abolish', 'malaise', 'fell', 'nebulously', 'miserableness', 'heckled', 'lambaste', 'rash', 'scourge', 'irked', 'warily', 'disconcert', 'downturn', 'flaws', 'unnerved', 'downfall', 'polluter', 'disconcerted', 'fragmented', 'grating', 'imposers', 'prate', 'anxious', 'blasphemous', 'damning', 'indiscriminately', 'guile', 'heinous', 'inhibition', 'disdain', 'concern', 'spoonfed', 'ridiculously', 'careless', 'inclement', 'crisis', 'antagonism', 'debauch', 'tarnishing', 'gloom', 'unstable', 'lost', 'gimmicking', 'ill-designed', 'illogically', 'neglected', 'languorous', 'scarce', 'smokescreen', 'unsound', 'vibrate', 'outlaw', 'slanders', 'contentious', 'fleeing', 'protest', 'denied', 'mudslinger', 'pest', 'beseech', 'bewilder', 'disrespectfulness', 'pitifully', 'extortion', 'objection', 'forged', 'lie', 'polemize', 'sloooooooooooooow', 'accusingly', 'autocratic', 'addicted', 'untouched', 'appal', 'gullible', 'adversary', 'entanglement', 'revengefully', 'swelled', 'loopholes', 'flagrant', 'villainous', 'anti-occupation', 'punishable', 'shame', 'feign', 'ploy', 'unjustified', 'miff', 'sceptical', 'spookiest', 'damaging', 'shamefully', 'tanks', 'misaligns', 'oblivious', 'wobbled', 'agonizingly', 'blatantly', 'delinquent', 'threatening', 'forsake', 'smoke', 'indignantly', 'somber', 'infidels', 'disintegrates', 'unwise', 'oversize', 'sadden', 'stuck', 'downturns', 'brazenness', 'tragedy', 'backaching', 'complained', 'misbecome', 'moribund', 'extremists', 'exasperating', 'overblown', 'addicts', 'disallow', 'bullyingly', 'steals', 'preoccupy', 'belittling', 'mawkishness', 'unworkable', 'sack', 'goading', 'repression', 'suffocate', 'disagree', 'hawkish', 'evasion', 'hard', 'stringently', 'crazy', 'lorn', 'pout', 'unfavorable', 'drab', 'incessant', 'languish', 'disclaim', 'capriciously', 'obstructed', 'struggled', 'irrationally', 'douchebags', 'heckle', 'presumptuously', 'turbulent', 'expropriation', 'leakage', 'prisoner', 'poor', 'authoritarian', 'calumniously', 'whiny', 'incommensurate', 'impatience', 'disaffect', 'gibber', 'havoc', 'halfheartedly', 'abysmal', 'regretful', 'coward', 'assassinate', 'damnation', 'stubborn', 'blatant', 'wripping', 'oddities', 'brutality', 'tramp', 'batty', 'obsessiveness', 'pandemonium', 'stutters', 'defamations', 'interruptions', 'unrest', 'bungling', 'unusual', 'sick', 'strike', 'racism', 'haze', 'unsuspecting', 'insupportable', 'trouble', 'appalled', 'insubstantially', 'ineffectualness', 'imprecise', 'acrid', 'condemn', 'corrosive', 'rot', 'negligence', 'tempest', 'conspicuously', 'discontinuous', 'bulkyness', 'irksomenesses', 'quibbles', 'tiresome', 'worthless', 'frighten', 'senseless', 'uncivil', 'undetermined', 'discoutinous', 'wrath', 'bashed', 'eviscerate', 'impair', 'subvert', 'crueler', 'inordinate', 'brazenly', 'cruelness', 'cramped', 'grumpy', 'fastidious', 'bellicose', 'mashed', 'haywire', 'ricer', 'rifts', 'break', 'quack', 'splatter', 'craze', 'boiling', 'angrily', 'bombastic', 'misbehave', 'mushy', 'diatribes', 'horrify', 'obsessively', 'opportunistic', 'disasterous', 'self-interested', 'monstrosity', 'catastrophies', 'devil', 'irrecoverably', 'pessimistic', 'remorseful', 'conspiracy', 'dungeon', 'fanatics', 'pittance', 'ax', 'imprudent', 'unavailable', 'insignificant', 'greedy', 'desititute', 'thicker', 'panicked', 'spewing', 'disgusted', 'suppress', 'incredulously', 'restricted', 'loath', 'retract', 'stuttered', 'unachievable', 'distressingly', 'imprecision', 'fallaciousness', 'grieve', 'incivility', 'impedance', 'hangs', 'bewitch', 'aborted', 'martyrdom-seeking', 'licentious', 'achey', 'protesting', 'subversive', 'dodgey', 'revolting', 'dejectedly', 'compulsion', 'sinful', 'fallout', 'shimmer', 'vagueness', 'apathetically', 'dishearteningly', 'enraged', 'lure', 'perversion', 'sarcastic', 'leaks', 'taut', 'spilling', 'wreaked', 'conflicts', 'disappointing', 'obsolete', 'cheat', 'disappoints', 'ineptly', 'irresolute', 'confession', 'mortify', 'overdone', 'oversimplify', 'overstatements', 'nefariously', 'accusation', 'overtaxed', 'insurrection', 'scarily', 'aloof', 'mar', 'subversively', 'picky', 'diametrically', 'puppets', 'ordeal', 'ill-favored', 'obliterated', 'condemnation', 'ineffectively', 'instigate', 'dissenter', 'scoffingly', 'cringed', 'infiltrator', 'screw-up', 'eruptions', 'hysterically', 'jerky', 'jeopardize', 'outrageousness', 'baffle', 'blindside', 'arrogant', 'cheaply', 'corruptted', 'drop-outs', 'oversights', 'wasteful', 'inexorable', 'lethargic', 'aching', 'murderously', 'ineloquent', 'backwoods', 'apprehensively', 'sickness', 'inexpiable', 'outmoded', 'spookily', 'ignominy', 'stereotypical', 'destruction', 'devilry', 'skinny', 'dreadfully', 'allergy', 'fathomless', 'murder', 'unintelligile', 'agonize', 'soapy', 'freaks', 'regression', 'slander', 'aggression', 'slanderer', 'scars', 'gripes', 'sin', 'infuriatingly', 'unhealthy', 'deplorable', 'inexplainable', 'imperil', 'fanatically', 'obnoxious', 'choleric', 'unfairly', 'distressed', 'gnawing', 'lambast', 'qualms', 'instigators', 'terrorism', 'criticize', 'mockeries', 'disvalue', 'grind', 'obtuse', 'thankless', 'bores', 'pigs', 'credulous', 'frigging', 'atrocious', 'catastrophically', 'disrupt', 'hogs', 'improper', 'infamy', 'scarcity', 'cataclysm', 'controversy', 'scowl', 'sink', 'helpless', 'devastates', 'cussed', 'mistake', 'humiliation', 'irrelevant', 'loss', 'loneliness', 'prejudice', 'disinterest', 'uncertain', 'astray', 'subjected', 'squeak', 'disgustedly', 'belittled', 'bitterly', 'stigma', 'sunder', 'devilishly', 'hack', 'mediocrity', 'cataclysmically', 'musty', 'incompatibility', 'disbelief', 'deceiver', 'impermissible', 'deadlock', 'extinguish', 'ghetto', 'second-class', 'inevitably', 'dick', 'bigotries', 'twist', 'alarm', 'crash', 'bewildered', 'detests', 'defiance', 'misinformed', 'impudent', 'relentlessness', 'neurotically', 'fatuous', 'reviled', 'begging', 'indolent', 'simplistically', 'fib', 'inflexible', 'slug', 'friggin', 'freeze', 'backward', 'confounded', 'fumble', 'congestion', 'dishonest', 'debility', 'displeasing', 'incompatible', 'indoctrination', 'allege', 'lukewarm', 'shocked', 'strange', 'stumps', 'vociferous', 'degradation', 'stolen', 'unruly', 'counterproductive', 'revoke', 'worryingly', 'hated', 'displeased', 'discriminatory', 'cons', 'culprit', 'disapprove', 'plea', 'barren', 'tank', 'immaterial', 'ultimatums', 'averse', 'slog', 'insult', 'layoff-happy', 'bothersome', 'unequal', 'crowded', 'capriciousness', 'detestably', 'repudiate', 'cynical', 'imbalance', 'fetid', 'inadequate', 'disrespectablity', 'hassle', 'flee', 'comical', 'gruesomely', 'gimmick', 'fierce', 'obese', 'tentative', 'suicide', 'deplore', 'fearsome', 'nauseate', 'admonition', 'oppressive', 'disappointment', 'scorching', 'cheesy', 'downhearted', 'impaired', 'impolitic', 'smoldering', 'erase', 'mundane', 'discouragement', 'impolitely', 'chagrin', 'indifferent', 'backwood', 'lackeys', 'infuriated', 'thoughtlessness', 'desultory', 'enrage', 'creep', 'humiliating', 'rancor', 'inferiority', 'prattle', 'vengeful', 'damnable', 'unhappily', 'strangely', 'confess', 'delinquency', 'two-faced', 'distorted', 'straggler', 'ailment', 'insouciance', 'wretchedness', 'unfortunately', 'zealot', 'jutter', 'disrepute', 'bruising', 'discordance', 'discrepant', 'mordantly', 'passive', 'inteferes', 'suffering', 'sags', 'splitting', 'blockage', 'implication', 'farce', 'bereave', 'frustrated', 'difficulties', 'grumpiest', 'obnoxiously', 'obscenity', 'dupe', 'unsuccessful', 'rigid', 'pricey', 'disgustingly', 'unwilling', 'worn', 'unresponsive', 'unproved', 'quibble', 'allegation', 'viper', 'deterioration', 'boycott', 'upset', 'butcher', 'overzealous', 'protests', 'disturbingly', 'surrender', 'imprecisely', 'tease', 'wiles', 'wrinkles', 'inexpert', 'scar', 'immovable', 'confound', 'fibber', 'mischievous', 'shortchange', 'sickeningly', 'struck', 'bullies', 'blabber', 'guiltily', 'misread', 'precariously', 'peeve', 'rile', 'squeaks', 'bewilderingly', 'effigy', 'corrode', 'inextricable', 'quarrel', 'nag', 'adversarial', 'hotbeds', 'pettifog', 'errors', 'stumbles', 'incapably', 'hoax', 'uproot', 'standstill', 'execrate', 'hotheaded', 'superficiality', 'corruption', 'malevolently', 'loose', 'belligerence', 'illusion', 'uncaring', 'misuse', 'problems', 'exaggeration', 'tout', 'radically', 'vociferously', 'cringes', 'subpoenas', 'rough', 'darken', 'bleak', 'fraudulent', 'rattle', 'insufferable', 'undocumented', 'regrettable', 'expel', 'fuzzy', 'virulently', 'overbalance', 'wretched', 'undercutting', 'ambiguity', 'sueing', 'hoodium', 'panic', 'explode', 'fist', 'onerously', 'rebuff', 'suppression', 'inadequacy', 'reproachful', 'poison', 'lividly', 'startling', 'inhumane', 'prejudicial', 'anti-proliferation', 'impatient', 'unwanted', 'persecution', 'risks', 'puzzling', 'flareups', 'despotism', 'bane', 'cravenly', 'disgruntled', 'brutish', 'glitches', 'incomparable', 'missed', 'bore', 'negativity', 'pariah', 'indiscriminate', 'rigidity', 'stammer', 'anarchism', 'breakups', 'cancer', 'inconsiderately', 'stridently', 'idiot', 'exasperated', 'anti-israeli', 'exterminate', 'reprovingly', 'lurid', 'miscalculation', 'spitefully', 'enslave', 'symptom', 'corrupting', 'reprehensible', 'pugnacity', 'concerned', 'scolded', 'harass', 'smallish', 'confuse', 'enraging', 'feebleminded', 'seething', 'illegally', 'ruffle', 'thoughtlessly', 'improbably', 'darkness', 'meanness', 'restless', 'junkyard', 'insanity', 'scuffs', 'distraught', 'misunderstandings', 'fusty', 'wack', 'maladjusted', 'misguide', 'remorselessly', 'dropout', 'hedonistic', 'unfaithfully', 'shortsightedness', 'gawk', 'derisiveness', 'burned', 'harmed', 'poorer', 'agonies', 'whores', 'demon', 'sickly', 'fanaticism', 'stooge', 'strain', 'dizzy', 'dissatisfied', 'aggrivation', 'useless', 'frustrates', 'spew', 'miserable', 'stupidly', 'implacable', 'aborts', 'flirt', 'downcast', 'pertinacious', 'flabbergasted', 'ill-usage', 'lag', 'subservient', 'unwisely', 'uncompromising', 'dislikes', 'insociable', 'insidiously', 'sensationalize', 'impoverished', 'loathing', 'ripped', 'insubordinate', 'craftily', 'sues', 'barbarically', 'unilateralism', 'drawback', 'vomit', 'vulnerable', 'touchy', 'fallacy', 'hardships', 'ineffective', 'grapple', 'dirts', 'lewdly', 'sucker', 'brutal', 'allergies', 'crushing', 'dismalness', 'complication', 'shameful', 'frost', 'stalemate', 'derision', 'humming', 'rejected', 'urgent', 'conflict', 'break-ups', 'inflated', 'quarrels', 'temerity', 'bulky', 'indefensible', 'glare', 'shrew', 'madden', 'devoid', 'friction', 'kaput', 'capsize', 'decadence', 'dirty', 'injustice', 'tepid', 'perverse', 'discrimination', 'fabrication', 'anti-social', 'dirtbags', 'nonsense', 'sullen', 'inconsistencies', 'misjudge', 'lowly', 'frustrations', 'reluctant', 'rail', 'brainwash', 'disturb', 'uncontrolled', 'dispiriting', 'judder', 'cheap', 'moron', 'cheating', 'irresponsibly', 'gawky', 'err', 'insufficient', 'pervasive', 'spoilled', 'unacceptablely', 'anxiously', 'debt', 'disinclined', 'felonious', 'lawlessness', 'scandalously', 'sob', 'disillusionment', 'cheater', 'crap', 'ill-treated', 'disadvantages', 'procrastinate', 'defiantly', 'repulsively', 'syndrome', 'inequality', 'distaste', 'craven', 'downbeat', 'heedless', 'bulkiness', 'thorny', 'stump', 'lonesome', 'regreted', 'slump', 'dawdle', 'imperfect', 'depressed', 'loot', 'inconsistency', 'unkindly', 'antagonistic', 'boring', 'sufferer', 'fried', 'panders', 'pervert', 'troublemaker', 'contrived', 'desertion', 'expropriate', 'ignominious', 'dogmatic', 'streaky', 'insecure', 'enemy', 'aches', 'arcane', 'hurtful', 'ineptitude', 'barbarous', 'notoriety', 'dislocated', 'horrifys', 'itch', 'spurn', 'intransigent', 'weariness', 'skeletons', 'dump', 'unfinished', 'audiciously', 'backwardness', 'woebegone', 'combust', 'burning', 'breach', 'morons', 'risk', 'brazen', 'downsides', 'battering', 'multi-polarization', 'sneering', 'slothful', 'painful', 'unsure', 'complaint', 'wrip', 'interrupt', 'bombardment', 'collude', 'overawe', 'opposition', 'unfit', 'brittle', 'hostage', 'needless', 'insensitive', 'irritant', 'inconceivable', 'distraction', 'stink', 'dissatisfies', 'reluctantly', 'askance', 'injudicious', 'dud', 'bumpping', 'freakish', 'busts', 'lackey', 'shriek', 'prosecute', 'displease', 'reactionary', 'torturously', 'remorselessness', 'abyss', 'fall', 'abort', 'flaky', 'rollercoaster', 'disintegrated', 'divisiveness', 'irately', 'bluring', 'nonexistent', 'patronize', 'inflationary', 'stereotypically', 'torturous', 'untrustworthy', 'giddy', 'preposterous', 'gruesome', 'fustigate', 'haphazard', 'inequities', 'wary', 'regress', 'desolate', 'angriness', 'propagandize', 'untruthful', 'imprisonment', 'disloyal', 'offensiveness', 'wedge', 'vengeance', 'stab', 'obstructs', 'snagged', 'weak', 'gossip', 'injure', 'eccentric', 'lies', 'deprived', 'ultimatum', 'snag', 'denounce', 'snagging', 'improbability', 'dubious', 'indelicate', 'malignant', 'stalls', 'imperiously', 'uproariously', 'fleed', 'intransigence', 'jagged', 'sarcasm', 'invidiousness', 'crass', 'lying', 'bumps', 'confined', 'disruptive', 'exhausts', 'intolerablely', 'rabid', 'smother', 'beg', 'convoluted', 'irate', 'indiscretion', 'brimstone', 'implausibly', 'erroneous', 'get-rich', 'glitch', 'lifeless', 'rip', 'sagged', 'selfish', 'ailing', 'unkind', 'unproves', 'condescend', 'skulk', 'bum', 'deceptively', 'parasite', 'dissuasive', 'disordered', 'rupture', 'tyrannical', 'mire', 'inevitable', 'brutalising', 'weirdly', 'shake', 'degradingly', 'facetious', 'dissidence', 'inconstant', 'deny', 'castigate', 'excoriate', 'smugly', 'fabricate', 'disliked', 'misconceptions', 'shimmy', 'interference', 'lags', 'destitute', 'paradoxical', 'roadblocks', 'issue', 'profanity', 'disarray', 'seethe', 'delirious', 'flareup', 'dripped', 'plight', 'cripple', 'dejected', 'grief', 'imperialist', 'chunky', 'incomprehension', 'dehumanization', 'stark', 'detract', 'succumb', 'unwillingly', 'hypocrites', 'flickering', 'devastated', 'finicky', 'glibly', 'obstruct', 'cruelty', 'non-confidence', 'plagiarize', 'repudiation', 'discomfit', 'vanity', 'anguish', 'blur', 'disorderly', 'liability', 'dismissively', 'discouraging', 'sputter', 'distract', 'misery', 'sorrowfully', 'ache', 'estranged', 'conspiracies', 'stutter', 'unreasonably', 'stole', 'partiality', 'discriminate', 'slave', 'blunt', 'fault', 'impede', 'mindless', 'resent', 'horrendously', 'subjection', 'coldly', 'harassment', 'hardliners', 'allegations', 'damaged', 'despicably', 'hefty', 'ail', 'chill', 'derisively', 'heavyhearted', 'insular', 'odd', 'slow-moving', 'strict', 'mistrust', 'punch', 'douchbag', 'crush', 'scratched', 'biased', 'despair', 'devious', 'disrespecting', 'defy', 'perversely', 'hobble', 'fumes', 'irredeemably', 'blurring', 'indecency', 'distort', 'petty', 'erratically', 'runaway', 'shambles', 'lackluster', 'lousy', 'despondence', 'foully', 'misbecoming', 'bowdlerize', 'anomaly', 'contempt', 'plotters', 'uncompromisingly', 'nauseating', 'misinterpret', 'disadvantageous', 'dispirit', 'pessimistically', 'rocky', 'disagreeing', 'bloodthirsty', 'hairloss', 'grumpier', 'haste', 'hellion', 'sharply', 'banalize', 'complains', 'nightmarish', 'silly', 'bewilderment', 'assassin', 'deceit', 'alarmingly', 'failing', 'debacle', 'preposterously', 'shemale', 'wrestle', 'dubiously', 'reluctance', 'tortured', 'lagged', 'bash', 'insults', 'nightmarishly', 'illogic', 'mock', 'pointless', 'hater', 'awkwardness', 'emptiness', 'poorest', 'sham', 'irritated', 'catastrophic', 'egomania', 'cackle', 'conceit', 'conceited', 'villian', 'brute', 'audacity', 'sinisterly', 'stagnation', 'betrays', 'daunting', 'badly', 'intimidatingly', 'panick', 'censure', 'disgruntle', 'pathetic', 'pertinaciously', 'stiflingly', 'whimper', 'cautionary', 'murderous', 'impugn', 'debase', 'gasp', 'imprison', 'scum', 'disconcertingly', 'impossibly', 'reject', 'droop', 'heresy', 'cramping', 'banish', 'casualty', 'recant', 'uneconomical', 'collapse', 'dissappointing', 'retaliatory', 'trash', 'overwhelmingly', 'unsteady', 'unconvincing', 'sloth', 'gape', 'dissatisfying', 'bump', 'dastard', 'resistance', 'demean', 'erode', 'irritably', 'knotted', 'sad', 'isolate', 'conspire', 'noise', 'decay', 'horde', 'subtract', 'fatalistic', 'predatory', 'busybody', 'sticky', 'totalitarian', 'wasting', 'oddly', 'hacks', 'horrendous', 'vibration', 'revile', 'spoiled', 'crabby', 'accuses', 'haunting', 'steep', 'despicable', 'unattractive', 'apathy', 'monotony', 'detriment', 'unfounded', 'raving', 'weaker', 'perfunctory', 'virulent', 'contaminate', 'overkill', 'vagrant', 'inconsistent', 'bizarre', 'deceitfulness', 'violator', 'fictitious', 'fevers', 'quandary', 'rut', 'racists', 'unravel', 'egregious', 'flagging', 'dastardly', 'dishonesty', 'stunted', 'suffers', 'inexorably', 'crappy', 'startlingly', 'bogus', 'infringe', 'intolerance', 'spoilage', 'ineloquently', 'unfriendly', 'tired', 'disgracefully', 'startle', 'controversial', 'imperfection', 'rivalry', 'deprive', 'bleeds', 'bungle', 'incessantly', 'naive', 'repulse', 'tenuously', 'incompetence', 'hazardous', 'disreputable', 'militancy', 'anti-american', 'distress', 'fooled', 'unpleasant', 'infraction', 'disgustful', 'niggle', 'jitter', 'lurking', 'wrought', 'improbable', 'slaughter', 'miscreant', 'interferes', 'disgraceful', 'irretrievable', 'commotions', 'prohibitively', 'incomplete', 'torrent', 'wearisome', 'problematic', 'ruining', 'spoon-feed', 'obscurity', 'smutty', 'embarrassing', 'propaganda', 'troubles', 'outraged', 'inhospitable', 'meddlesome', 'squeaky', 'lewdness', 'defect', 'nave', 'debaser', 'derisive', 'degenerately', 'detestable', 'deaf', 'severity', 'tedious', 'vexingly', 'despoil', 'cunt', 'lengthy', 'cunts', 'invalidate', 'infringement', 'plot', 'annoy', 'vibrating', 'impurity', 'savages', 'abscond', 'disaster', 'bitch', 'bondage', 'bumpy', 'defrauding', 'pugnaciously', 'degrade', 'scarier', 'fleer', 'strangest', 'toil', 'slowww', 'hurting', 'perilous', 'absurdity', 'betrayals', 'skeptically', 'insensible', 'miseries', 'spooky', 'unlamentable', 'menace', 'obstruction', 'gibberish', 'rogue', 'precipitate', 'throbbed', 'invidious', 'torment', 'blurt', 'complicated', 'misrepresent', 'onslaught', 'strangle', 'strenuous', 'uncivilized', 'undid', 'wrongly', 'cliched', 'disproportionate', 'raked', 'donside', 'embarrass', 'unqualified', 'skittishly', 'peculiar', 'unnaturally', 'ruthlessness', 'disses', 'defamation', 'regretfully', 'spiritless', 'uproarious', 'blather', 'buggy', 'overpriced', 'disparage', 'expensive', 'un-viewable', 'despairing', 'inescapable', 'reprehensibly', 'hothead', 'bullying', 'disrespectfully', 'untenable', 'unscrupulous', 'redundant', 'obsess', 'vain', 'tortures', 'tumbles', 'wayward', 'irrationalities', 'snobs', 'soreness', 'mockingly', 'dilly-dally', 'trauma', 'worsening', 'inaccurately', 'altercation', 'diabolical', 'treacherous', 'crumpled', 'losers', 'touted', 'wripped', 'blistering', 'feckless', 'struggle', 'fiction', 'undermines', 'cronyism', 'dread', 'beguile', 'corrosions', 'expunge', 'pretentious', 'misapprehend', 'turmoil', 'disappointed', 'uncompetitive', 'burdensomely', 'fanatical', 'unsecure', 'infuriating', 'squirm', 'pitiable', 'arrogance', 'bribery', 'alarming', 'ill-fated', 'stifling', 'subpoena', 'outbursts', 'distorts', 'inadverently', 'unexplained', 'treachery', 'insidious', 'devastatingly', 'liars', 'measly', 'static', 'retarded', 'sourly', 'relapse', 'unworthy', 'uncomfy', 'harangue', 'livid', 'barbarity', 'inexperienced', 'irritating', 'sucks', 'vengefully', 'selfishly', 'unsupported', 'ranted', 'malicious', 'faithless', 'barbaric', 'fear', 'infamously', 'distains', 'juddering', 'conspiratorial', 'admonishment', 'genocide', 'inappropriately', 'botch', 'conscons', 'oppression', 'whips', 'drunken', 'garbage', 'perversity', 'condescendingly', 'forswear', 'tricked', 'ugly', 'unbelievable', 'brutalities', 'repugn', 'imbecile', 'grossly', 'sorrowful', 'stooges', 'bleeding', 'regrettably', 'inhuman', 'stupified', 'expired', 'inescapably', 'mischievously', 'fatigue', 'rascals', 'uprising', 'evils', 'devilish', 'dismay', 'nervously', 'predicament', 'hostility', 'perilously', 'irksomely', 'ruts', 'defunct', 'anger', 'fickle', 'uglier', 'forgetfulness', 'refutes', 'slaughtered', 'intrusion', 'unbearablely', 'obscenely', 'oppressively', 'floored', 'deadweight', 'irrational', 'devastation', 'unconvincingly', 'gimmicked', 'debauchery', 'temper', 'appall', 'steal', 'powerless', 'exhausted', 'attack', 'erosion', 'hegemonism', 'precipitous', 'worried', 'contemptuous', 'disoobedient', 'bitterness', 'creak', 'haters', 'accuse', 'deprecate', 'downfallen', 'elimination', 'intrusive', 'coupists', 'polarisation', 'collusion', 'discontinued', 'ashamed', 'falsehood', 'sub-par', 'adulterier', 'deadly', 'killing', 'smelt', 'wickedness', 'tetchy', 'pales', 'bust', 'slut', 'flake', 'insufficiently', 'tiringly', 'crazily', 'infested', 'joke', 'drags', 'irredeemable', 'sadly', 'slogged', 'pitilessly', 'beware', 'infidel', 'rremediable', 'crumple', 'boredom', 'vice', 'mad', 'breaks', 'secretive', 'self-defeating', 'corrosion', 'deviation', 'overplay', 'unacceptable', 'starve', 'abruptly', 'deviously', 'impatiently', 'illicit', 'pernicious', 'inordinately', 'quitter', 'immobilized', 'treasonous', 'stiffness', 'eyesore', 'boggle', 'ignorant', 'lesser-known', 'gallingly', 'humid', 'upheaval', 'violators', 'scams', 'anti-white', 'critics', 'scrambling', 'denies', 'traped', 'unsafe', 'futility', 'senselessly', 'disbelieve', 'admonisher', 'insecurity', 'grouch', 'complain', 'obstinate', 'procrastinates', 'stench', 'apocalypse', 'misguidance', 'unsettling', 'fainthearted', 'dropouts', 'stranger', 'stupidest', 'shortage', 'annoyances', 'oppress', 'desperate', 'indifference', 'unforeseen', 'irregular', 'bruises', 'hate', 'brutally', 'horrible', 'salacious', 'absurd', 'deficient', 'tarnishes', 'undissolved', 'disquiet', 'nervous', 'uncomfortable', 'creeping', 'deficiencies', 'fastidiously', 'franticly', 'guilt', 'inaction', 'virus', 'back-logged', 'miserly', 'grimace', 'autocrat', 'rattles', 'mortified', 'refuses', 'undue', 'wicked', 'chasten', 'panicky', 'refuted', 'wasted', 'thug', 'frustration', 'rumor', 'blasphemy', 'stain', 'unlucky', 'afflictive', 'afraid', 'mope', 'inaptitude', 'ridicule', 'cheats', 'intimidating', 'annihilate', 'extravagance', 'monstrosities', 'refusal', 'plunder', 'disobedience', 'jeering', 'mispronounced', 'implausible', 'scathingly', 'graceless', 'hypocritical', 'trapped', 'fanatic', 'belated', 'myth', 'false', 'fugitive', 'disastrously', 'unwatchable', 'ghosting', 'greasy', 'discredit', 'swelling', 'flees', 'flakieness', 'bestial', 'horrified', 'jitters', 'brainless', 'chide', 'nauseatingly', 'sinking', 'whine', 'intimidate', 'bearish', 'hasseling', 'tattered', 'incoherence', 'frail', 'shortcomings', 'faze', 'forbid', 'dungeons', 'imperfectly', 'mirage', 'traduce', 'satirize', 'feeblely', 'arduous', 'unwieldy', 'indeterminate', 'embattled', 'hallucination', 'zealous', 'expulse', 'clique', 'unuseable', 'officious', 'undermined', 'unfunded', 'infringements', 'hectic', 'vengefulness', 'fulminate', 'flair', 'avaricious', 'frown', 'noises', 'throbbing', 'cliche', 'tumbled', 'apprehensive', 'outsider', 'distrustful', 'overstatement', 'threaten', 'fracture', 'aspersion', 'vexing', 'shrilly', 'condescending', 'falls', 'inelegant', 'fidget', 'curt', 'heathen', 'diabolically', 'disarm', 'groundless', 'indiscreetly', 'marginally', 'wreak', 'jealous', 'hasty', 'wastefulness', 'smolder', 'ugliness', 'insinuation', 'illegitimate', 'harasses', 'repulsive', 'starkly', 'unrelenting', 'disturbed', 'malice', 'sugar-coated', 'twisted', 'insulted', 'bristle', 'paralyzed', 'jobless', 'flimsy', 'messes', 'tamper', 'damage', 'destroy', 'anarchistic', '2-faced', 'ranting', 'disingenuous', 'misconception', 'aimless', 'sorry', 'sued', 'acrimoniously', 'abuses', 'unpopular', 'unsavory', 'disregard', 'leakages', 'longing', 'harboring', 'unwelcome', 'distrust', 'unraveled', 'bumped', 'dissatisfaction', 'qualm', 'squeal', 'offending', 'deplete', 'intolerable', 'ding', 'gainsay', 'lunatic', 'ineffectiveness', 'froze', 'dissocial', 'shadowy', 'horrific', 'adverse', 'drought', 'fat', 'loathe', 'reproach', 'frustrate', 'detesting', 'catastrophes', 'frozen', 'inefficacy', 'brood', 'presumptuous', 'relentlessly', 'illogical', 'deceiving', 'noisier', 'uneasiness', 'worthlessly', 'unhelpful', 'ambivalence', 'caustically', 'drowning', 'faulty', 'sicken', 'shabby', 'life-threatening', 'angry', 'inextricably', 'intense', 'hypocricy', 'criminal', 'contention', 'infected', 'declines', 'criticisms', 'dispiritedly', 'disconsolation', 'inability', 'destains', 'itching', 'irritate', 'forceful', 'steeply', 'chore', 'job-killing', 'defamatory', 'ominous', 'perish', 'sardonically', 'crushed', 'raging', 'unclear', 'unnerving', 'lose', 'disdainfully', 'leaky', 'drawbacks', 'fail', 'sour', 'extravagant', 'zealously', 'blameworthy', 'checkered', 'aggressiveness', 'beggarly', 'cloud', 'awfully', 'freezes', 'ragged', 'miser', 'obstructing', 'unthinkably', 'misrepresentation', 'penalize', 'stagnate', 'unwell', 'setback', 'divergent', 'flaking', 'fright', 'demeaning', 'cursed', 'overact', 'sucky', 'harridan', 'ineligible', 'sluts', 'sporadic', 'whore', 'absentee', 'atrophy', 'cash-strapped', 'engulf', 'partisan', 'topple', 'manic', 'retardedness', 'moan', 'worrier', 'sagging', 'screwed', 'slowest', 'pique', 'wariness', 'flabbergast', 'grudgingly', 'worthlessness', 'enjoin', 'cutthroat', 'impiety', 'awkward', 'gauche', 'invalid', 'untrue', 'danger', 'asinine', 'exasperate', 'limitations', 'sidetrack', 'quash', 'failure', 'imbroglio', 'moot', 'abysmally', 'sloow', 'scoldingly', 'disingenuously', 'anarchist', 'chatter', 'glower', 'laughably', 'anemic', 'egotistically', 'racist', 'impractical', 'disrespectful', 'irrecoverablenesses', 'subjugate', 'mediocre', 'hard-hit', 'deceive', 'barbarian', 'goofy', 'sunk', 'brusque', 'foreboding', 'loud', 'crafty', 'paranoia', 'vicious', 'crumples', 'ruffian', 'drones', 'irksome', 'decadent', 'slime', 'overzealously', 'feverish', 'protested', 'monstrous', 'heckles', 'ironical', 'impending', 'exorbitantance', 'weed', 'exagerated', 'incredulous', 'truant', 'explosive', 'distressing', 'nonresponsive', 'dogged', 'irreversible', 'maniac', 'clog', 'revulsive', 'torture', 'vileness', 'flimflam', 'flak', 'devastating', 'lamentable', 'layoff', 'despot', 'taint', 'violation', 'chaos', 'licentiousness', 'terrorize', 'lethal', 'meltdown', 'smut', 'subdued', 'worsen', 'offender', 'impenitent', 'stupidity', 'rant', 'shamelessness', 'inimically', 'maddening', 'scold', 'hazard', 'apprehensions', 'victimize', 'complaining', 'undecided', 'demonized', 'bereft', 'polluters', 'inconsolable', 'decrepit', 'fatalistically', 'gabble', 'chilly', 'leak', 'bemused', 'fatefully', 'hideous', 'horrid', 'slaves', 'unlicensed', 'affliction', 'concede', 'disappointments', 'downer', 'jam', 'jeer', 'misguided', 'worriedly', 'antithetical', 'inelegance', 'disregardful', 'agony', 'debasement', 'excuses', 'remorseless', 'jumpy', 'idiots', 'slack', 'errant', 'muddy', 'inapt', 'snub', 'irrecoverable', 'stodgy', 'dictator', 'peril', 'sass', 'split', 'absurdness', 'agonizing', 'disintegration', 'annoys', 'brash', 'hard-liner', 'melodramatically', 'plague', 'helplessness', 'hysterics', 'ravage', 'mortification', 'stumbled', 'wilt', 'gutter', 'undependability', 'spinster', 'dripping', 'shortness', 'imperfections', 'blab', 'hegemony', 'damnably', 'shady', 'hells', 'horrifies', 'sillily', 'scorn', 'rip-off', 'short-lived', 'skepticism', 'nasty', 'unjustly', 'untested', 'inequalities', 'annoyance', 'disputed', 'hissed', 'self-serving', 'bonkers', 'assault', 'traumatically', 'condemnable', 'dark', 'fallaciously', 'mobster', 'dust', 'absent-minded', 'farcically', 'hates', 'savage', 'substandard', 'lier', 'incorrectly', 'geezer', 'insufficiency', 'perverts', 'discordant', 'calamitously', 'perplexity', 'punk', 'intimidation', 'confrontation', 'harassed', 'unthinkable', 'dismayingly', 'mistress', 'deceivers', 'disadvantage', 'stereotype', 'offensive', 'nemesis', 'pretense', 'vehemently', 'decrement', 'desert', 'laughingstock', 'overdue', 'demolish', 'swollen', 'impeach', 'throbs', 'regretted', 'confusions', 'disaffected', 'avarice', 'rife', 'repugnantly', 'poky', 'unreasonable', 'skeptic', 'lame-duck', 'over-acted', 'belabor', 'byzantine', 'falsely', 'eschew', 'despoiler', 'screwed-up', 'back-wood', 'desolately', 'throttle', 'jerk', 'miscellaneous', 'darker', 'self-humiliation', 'ire', 'misleadingly', 'tension', 'refusing', 'nitpick', 'bankrupt', 'treason', 'gaffe', 'dim', 'wreaks', 'heartbreaker', 'bias', 'conflicted', 'trap', 'egocentric', 'injustices', 'unreadable', 'fragile', 'mishandle', 'ruinous', 'slanderously', 'inaccurate', 'noisy', 'suicidal', 'failures', 'hardened', 'enviousness', 'fails', 'heretic', 'confuses', 'unsustainable', 'impious', 'scratchy', 'die-hard', 'discouragingly', 'dishonor', 'dumping', 'ruined', 'shamefulness', 'berate', 'smear', 'disgrace', 'demoralizing', 'rape', 'poorly', 'eccentricity', 'recoil', 'taunts', 'revulsion', 'doldrums', 'blockhead', 'exagerate', 'zaps', 'dismally', 'wobble', 'suspicious', 'domineer', 'mindlessly', 'earsplitting', 'insolence', 'sobering', 'wild', 'choppy', 'contaminates', 'disagreeable', 'drain', 'inequitably', 'overpaid', 'irritable', 'whining', 'egotistical', 'scandal', 'denunciate', 'upsetting', 'break-up', 'monster', 'hastily', 'headaches', 'disfavor', 'unjust', 'desperately', 'washed-out', 'imprecate', 'wily', 'dissension', 'insurmountable', 'languid', 'perplexed', 'skimpy', 'underpowered', 'bothering', 'diappointed', 'detracted', 'disgusting', 'subjugation', 'denying', 'defective', 'madly', 'malodorous', 'overdo', 'foolishly', 'burns', 'lawless', 'flicker', 'paralize', 'picketed', 'wickedly', 'avariciously', 'wrongful', 'concen', 'bicker', 'excruciatingly', 'decline', 'limit', 'tediously', 'defame', 'transgression'}\n"
          ]
        }
      ],
      "source": [
        "download(\"positive-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/positive-words.txt\")\n",
        "download(\"negative-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/negative-words.txt\")\n",
        "\n",
        "hu_liu_pos = load_hu_liu(\"positive-words.txt\")\n",
        "print('Positive words')\n",
        "print(hu_liu_pos)\n",
        "\n",
        "print()\n",
        "\n",
        "hu_liu_neg = load_hu_liu(\"negative-words.txt\")\n",
        "print('Negative words')\n",
        "print(hu_liu_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzWuXxEq9INJ"
      },
      "source": [
        "The words in the list are general, but we can add some extra items (\"`|`\" is the \"set union\" operator)\n",
        "\n",
        "This is especially helpful to couple with domain-specific terminology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XHAevZFs9INK"
      },
      "outputs": [],
      "source": [
        "airline_pos_words = hu_liu_pos | {\"upgrade\"}\n",
        "airline_neg_words = hu_liu_neg | {\"wtf\", \"wait\", \"waiting\", \"epicfail\", \"mechanical\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w7GIElE9INL"
      },
      "source": [
        "_Performance note:_ we use sets here (denoted with braces: `{...}`) rather than lists (with square brackets: `[...]`) to make lookup faster\n",
        "\n",
        "To track times, you can add %%timeit at the start of the execution block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy45mfQ79INL",
        "outputId": "645c9cec-4e9e-4179-bf71-be1383135fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46.5 ns ± 1.17 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1000000\n",
        "# -n represents the number of times the code will be executed during each test run (LOOPS)\n",
        "# we will have more test runs (7 by default)\n",
        "\n",
        "\"e\" in [\"a\", \"b\", \"c\", \"d\", \"e\"]   # list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADOFvNSD9INN",
        "outputId": "6f598067-24df-4a72-97c4-1e40e616f23a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.3 ns ± 0.764 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1000000\n",
        "\"e\" in {\"a\", \"b\", \"c\", \"d\", \"e\"}   # set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8XH_H6d9INP"
      },
      "source": [
        "### Text tokenization\n",
        "\n",
        "We have to decompose tweets into the single words they contain in order to search for the opinion words within it\n",
        "\n",
        "A _tokenization_ algorithm splits a text string into a sequence of _tokens_ each representing a single word (or other entities such as numbers and punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSDplc_P9INP"
      },
      "source": [
        "A simple tokenization algorithm can consist in removing all characters different from letters and spaces from text, than splitting text in words using spaces as boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TJORMSRs9INP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Considering \"This isn't a test, or is it?\" sentence as text\n",
        "# re.sub(\"[^A-Za-z ]\", \"\", text) will transform it as 'This isnt a test or is it'.\n",
        "# In general, it removes (that is equivalent to: substitute with \"\") every character that is not a upperase/lowercase letter or space\n",
        "def my_tokenizer(text):\n",
        "    # split(\" \") is used to split the sentence in a list of strings using the space \" \" as separator\n",
        "    return re.sub(\"[^A-Za-z ]\", \"\", text).split(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw9xbtIU9INQ"
      },
      "source": [
        "An example usage is..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6juY_S9INR",
        "outputId": "ee4eb61c-676d-46ab-c6e3-a728926f104a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This', 'isnt', 'a', 'test', 'or', 'is', 'it']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_tokenizer(\"This isn't a test, or is it?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFoRFRJM9INS"
      },
      "source": [
        "NLTK provides a finer tokenization algorithm, based on a knowledge model of the English language: in order to make it work, we have first to download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnBPTc5E9INT",
        "outputId": "877a65a0-f633-4c88-bcb7-f99831b971e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/jcbraz/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\") # PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS5JsR0E9INU"
      },
      "source": [
        "We can then use the `word_tokenize` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su1bApvb9INU",
        "outputId": "52b6c141-7499-48e8-860c-d28705a5d8eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.word_tokenize(\"This isn't a test, or is it?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuN515Y9INW"
      },
      "source": [
        "Other than keeping punctuation marks as separate tokens, NLTK was able to correctly split \"isn't\" into its two component words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trAmVK-69INX"
      },
      "source": [
        "### Sentiment scoring\n",
        "\n",
        "We define a function to compute the \"sentiment score\" of some text, computed as the difference between counts of positive and negative opinion words contained in it. Notice we have to convert all words in lowercase to be sure to find them in the lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "walyIml89INX"
      },
      "outputs": [],
      "source": [
        "def sentiment_score(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # count 1 for each word present in the positive words list\n",
        "    pos_matches = sum(1 for word in words if word.lower() in pos_words)\n",
        "    # same count with the negative words list\n",
        "    neg_matches = sum(1 for word in words if word.lower() in neg_words)\n",
        "    # return the difference between the two counts\n",
        "    return pos_matches - neg_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEiDe6fv9INZ"
      },
      "source": [
        "This functions accept the lists of positive and negative words as input, we can wrap it in a version specific for the \"airline\" opinion words lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "njkdCZha9INZ"
      },
      "outputs": [],
      "source": [
        "def airline_sentiment_score(text):\n",
        "    return sentiment_score(text, airline_pos_words, airline_neg_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwKz63o99INb"
      },
      "source": [
        "Example: a sentence with one positive word..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsCtI9SU9INb",
        "outputId": "6aa9db35-65aa-443e-b15d-8c7fe455e712"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airline_sentiment_score(\"This is an awesome test!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aQ1fUrK9INd"
      },
      "source": [
        "Let's consider a small set of sample sentences to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DvZj3Qg59INd"
      },
      "outputs": [],
      "source": [
        "sample = [\n",
        "    \"You're awesome and I love you\",\n",
        "    \"I hate and hate and hate. So angry. Die!\",\n",
        "    \"Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVxGd4jj9INf"
      },
      "source": [
        "We can use `map` to apply the scoring function to each of the samples and get the sequence of corresponding scores wrapped in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8hzGXMsQ9INf"
      },
      "outputs": [],
      "source": [
        "sample_scores = list(map(airline_sentiment_score, sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ5dPnud9INh",
        "outputId": "bb6cdadf-8242-4424-8e92-2d28a2fe832b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, -5, 4]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I306cBAA9INj"
      },
      "source": [
        "Using a pandas DataFrame, we can get a table of sample sentences matched with scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kWoqjh6f9INk",
        "outputId": "a946e234-f948-4f76-8e08-c6b20a6ce945"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>You're awesome and I love you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5</td>\n",
              "      <td>I hate and hate and hate. So angry. Die!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   score  \\\n",
              "0      2   \n",
              "1     -5   \n",
              "2      4   \n",
              "\n",
              "                                                                                     text  \n",
              "0                                                           You're awesome and I love you  \n",
              "1                                                I hate and hate and hate. So angry. Die!  \n",
              "2  Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\"score\": sample_scores, \"text\": sample})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4iDxy-y9INl"
      },
      "source": [
        "As we can see, the scoring function correctly evaluates straightforward sentences, although it fails to detect more elaborate text (e.g. using sarcasm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDmm8AT2Fsxn"
      },
      "source": [
        "Sarcasm is still something difficult to manage with today's language models\n",
        "\n",
        "See:\n",
        "- https://huggingface.co/siebert/sentiment-roberta-large-english\n",
        "- https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
        "- https://huggingface.co/helinivan/english-sarcasm-detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAPiIBPC9INl"
      },
      "source": [
        "Let's apply the scoring functions to all tweets for one of the companies, e.g. Delta. We wrap scores in a pandas Series so we can use its functionalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UHfh_kQf9INm"
      },
      "outputs": [],
      "source": [
        "delta_scores = pd.Series(map(airline_sentiment_score, tweets[\"text\"][tweets[\"airline\"] == \"delta\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XANhbzGVgva_",
        "outputId": "9b1dda2e-ed46-4be5-d573-53e8aefb4164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       0\n",
              "3      -1\n",
              "4       0\n",
              "       ..\n",
              "1140   -1\n",
              "1141   -1\n",
              "1142    0\n",
              "1143    0\n",
              "1144    0\n",
              "Length: 1145, dtype: int64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTqV-3Y19INn"
      },
      "source": [
        "We can get for example the mean score of tweets..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SX8uoX49INo",
        "outputId": "2bdf81fd-2b17-4fff-ac35-0142c834e543"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23231441048034934"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAM9PgZ9INp"
      },
      "source": [
        "...and even plot an histogram of the distribution of scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "IdnDfrX49INq",
        "outputId": "1575ad07-738f-4a17-d5af-43b12bbc55a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "delta_scores.plot.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0TSBjii9INr"
      },
      "source": [
        "Let's now work with the whole collection of tweets related to all airlines\n",
        "\n",
        "We compute sentiment scores for each tweet by applying the `airline_sentiment_score` function to the `text` columns; scores are saved in a `score` column added to a copy of the `tweets` DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-DsQ0Pd39INr"
      },
      "outputs": [],
      "source": [
        "tweets_with_scores = tweets.copy() # to leave unchanged the tweets DataFramce\n",
        "tweets_with_scores[\"score\"] = tweets_with_scores[\"text\"].apply(airline_sentiment_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOG2mmQe9INs"
      },
      "source": [
        "Let's see some random rows from it..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O6sqT54S9INt",
        "outputId": "6dd27643-1992-4609-afd9-8cd38fb44124"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>united</td>\n",
              "      <td>@united out of 5 #united segments 4 were sharp on time - but the last one DEN - YYC is delayed now.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2059</th>\n",
              "      <td>jetblue</td>\n",
              "      <td>@EileenCCampos @USAirways @JetBlue I miss the latter too. Thxx Eileen. Long day.</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>americanair</td>\n",
              "      <td>@lindzzescott @emirates @AmericanAir @British_Airways aviation is definitely the new cool!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>delta</td>\n",
              "      <td>RT @CNNTravel: Delta reviewing video to determine how boy hopped flight to Las Vegas: http://t.c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>delta</td>\n",
              "      <td>@VirginAustralia why is it ur planes r great and ur partner @Delta are terrible? Im on 1 now its...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          airline  \\\n",
              "3864       united   \n",
              "2059      jetblue   \n",
              "1919  americanair   \n",
              "557         delta   \n",
              "135         delta   \n",
              "\n",
              "                                                                                                     text  \\\n",
              "3864  @united out of 5 #united segments 4 were sharp on time - but the last one DEN - YYC is delayed now.   \n",
              "2059                     @EileenCCampos @USAirways @JetBlue I miss the latter too. Thxx Eileen. Long day.   \n",
              "1919           @lindzzescott @emirates @AmericanAir @British_Airways aviation is definitely the new cool!   \n",
              "557   RT @CNNTravel: Delta reviewing video to determine how boy hopped flight to Las Vegas: http://t.c...   \n",
              "135   @VirginAustralia why is it ur planes r great and ur partner @Delta are terrible? Im on 1 now its...   \n",
              "\n",
              "      score  \n",
              "3864      0  \n",
              "2059     -1  \n",
              "1919      1  \n",
              "557       0  \n",
              "135      -1  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_with_scores.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6S53XS9INu"
      },
      "source": [
        "### Summarizing sentiment for each company\n",
        "\n",
        "Let’s focus our analysis only on very negative (score <= 2) and very positive (score >= 2) tweets, adding columns which identify them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UNKPLeHv9INu"
      },
      "outputs": [],
      "source": [
        "tweets_with_scores[\"very_pos\"] = tweets_with_scores[\"score\"] >= 2\n",
        "tweets_with_scores[\"very_neg\"] = tweets_with_scores[\"score\"] <= -2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUiKdp6G9INx"
      },
      "source": [
        "We group the frame by companies, keeping just the columns indicating very positive or negative tweets and counting the number of them for each group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BLlyCc2u9INx"
      },
      "outputs": [],
      "source": [
        "twitter_score = tweets_with_scores.groupby(\"airline\")[[\"very_pos\", \"very_neg\"]].sum().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmBFK-U9INz"
      },
      "source": [
        "Let's view the obtained grouped table..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "KEzM87Un9IN0",
        "outputId": "afb9ef5a-3b07-408b-fbf9-8ace62281fc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>117</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg\n",
              "airline                         \n",
              "americanair        118        31\n",
              "delta              116        56\n",
              "jetblue             10         2\n",
              "southwestair       122        34\n",
              "united             117       101"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In3HBOxx9IN2"
      },
      "source": [
        "`airline` is now the _index_ of the frame: values of the index identify each row (much like a primary key in a database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQLL_qnb9IN2"
      },
      "source": [
        "For every company, we compute the sum of very positive and very negative tweets..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "c8cE82zg9IN2"
      },
      "outputs": [],
      "source": [
        "twitter_score[\"all_count\"] = twitter_score.very_pos + twitter_score.very_neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFcIG4YN9IN4"
      },
      "source": [
        "...then we compute a \"global sentiment score\" as the percentage between the count of positive tweets and the total count of tweets above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1UwlgKs19IN5"
      },
      "outputs": [],
      "source": [
        "twitter_score[\"score\"] = 100 * twitter_score.very_pos / twitter_score.all_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNz_-VSt9IN7"
      },
      "source": [
        "Let's now list the companies ranked by their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "KlEyMUuX9IN7",
        "outputId": "8233d1d9-444c-4a77-9841-56649bae5783"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "      <th>all_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>83.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "      <td>149</td>\n",
              "      <td>79.195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "      <td>156</td>\n",
              "      <td>78.205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>56</td>\n",
              "      <td>172</td>\n",
              "      <td>67.442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>117</td>\n",
              "      <td>101</td>\n",
              "      <td>218</td>\n",
              "      <td>53.670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg  all_count   score\n",
              "airline                                            \n",
              "jetblue             10         2         12  83.333\n",
              "americanair        118        31        149  79.195\n",
              "southwestair       122        34        156  78.205\n",
              "delta              116        56        172  67.442\n",
              "united             117       101        218  53.670"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_score.sort_values(\"score\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pav5BKXF9IN8"
      },
      "source": [
        "To simplify subsequent tests, we create a function which, given a series of scores for tweets, executes the steps above to extract summary scores for each airline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VNj8OLsF9IN8"
      },
      "outputs": [],
      "source": [
        "def get_summary_scores(tweet_scores):\n",
        "    very_pos_tweets = tweet_scores >= 2\n",
        "    very_neg_tweets = tweet_scores <= -2\n",
        "    very_pos = very_pos_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    very_neg = very_neg_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    total = very_pos + very_neg\n",
        "    return 100 * (very_pos / total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Img7WOX9IN-"
      },
      "source": [
        "### Comparing results with known customer satisfaction\n",
        "\n",
        "We can extract known information about the general satisfaction of airline companies from the ACSI (_American Customer Satisfaction Index_) website\n",
        "\n",
        "A table of the satisfaction index by year about airline companies is available at\n",
        "\n",
        "https://web.archive.org/web/20200203093734/https://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\n",
        "\n",
        "<!-- http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines -->\n",
        "\n",
        "We can import such data and use it to validate the satisfaction score extracted from Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWYVF1x09IN-"
      },
      "source": [
        "Pandas provides the `read_html` function to get DataFrames by scraping tables from a Web page (the `lxml` and `BeautifulSoup4` packages must be installed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PzQcr8ci9IN-"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "# it overrides the default function for context creation with the function to create an unverified context\n",
        "# namely to disable certificate verification\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "acsi_table = pd.read_html(\n",
        "    \"https://web.archive.org/web/20200203093734/https://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\",\n",
        "    header=0, index_col=0)[1]\n",
        "\n",
        "# use the local copy of ACSI table just in case of network troubles\n",
        "# acsi_table = pd.read_html(\"https://www.dropbox.com/s/xgkqtcd9bu6jres/acsi_arlines.html?raw=1\",\n",
        "#    header=0, index_col=0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_-CPi6_M9IOA",
        "outputId": "6347b74f-2f6f-4043-b9e0-1c1c44dc4062"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>Previous Year % Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>77.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Southwest</th>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JetBlue</th>\n",
              "      <td>80.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airlines</th>\n",
              "      <td>72.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American</th>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>-1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Others</th>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegiant</th>\n",
              "      <td>65.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-4.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United</th>\n",
              "      <td>68.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frontier</th>\n",
              "      <td>66.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              16    17    18    19  Previous Year % Change\n",
              "Alaska      77.0  78.0  79.0  80.0                     1.3\n",
              "Southwest   80.0  80.0  80.0  79.0                    -1.3\n",
              "JetBlue     80.0  82.0  79.0  79.0                     0.0\n",
              "Delta       71.0  76.0  74.0  75.0                     1.4\n",
              "Airlines    72.0  75.0  73.0  74.0                     1.4\n",
              "American    72.0  76.0  74.0  73.0                    -1.4\n",
              "All Others  74.0  74.0  73.0  71.0                    -2.7\n",
              "Allegiant   65.0  71.0  74.0  71.0                    -4.1\n",
              "United      68.0  70.0  67.0  70.0                     4.5\n",
              "Frontier    66.0  63.0  62.0  64.0                     3.2"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.iloc[:10,-5:] # display the first ten rows (airlines) and the last five columuns (years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "vz8CFcpZlqaJ",
        "outputId": "364c1e0b-0d19-454f-e359-0ebcfa3d384a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14, 27)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>Previous Year % Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>75</td>\n",
              "      <td>77.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Southwest</th>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>78</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JetBlue</th>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "      <td>81</td>\n",
              "      <td>80.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airlines</th>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>72.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American</th>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>-1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Others</th>\n",
              "      <td>72</td>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegiant</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>65</td>\n",
              "      <td>65.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-4.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United</th>\n",
              "      <td>62</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frontier</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>58</td>\n",
              "      <td>66.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            13  14  15    16    17    18    19  Previous Year % Change\n",
              "Alaska      NM  NM  75  77.0  78.0  79.0  80.0                     1.3\n",
              "Southwest   81  78  78  80.0  80.0  80.0  79.0                    -1.3\n",
              "JetBlue     83  79  81  80.0  82.0  79.0  79.0                     0.0\n",
              "Delta       68  71  71  71.0  76.0  74.0  75.0                     1.4\n",
              "Airlines    69  69  69  72.0  75.0  73.0  74.0                     1.4\n",
              "American    65  66  66  72.0  76.0  74.0  73.0                    -1.4\n",
              "All Others  72  70  73  74.0  74.0  73.0  71.0                    -2.7\n",
              "Allegiant   NM  NM  65  65.0  71.0  74.0  71.0                    -4.1\n",
              "United      62  60  60  68.0  70.0  67.0  70.0                     4.5\n",
              "Frontier    NM  NM  58  66.0  63.0  62.0  64.0                     3.2"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(acsi_table.shape) # 14 rows, 27 columns\n",
        "acsi_table.iloc[:10,-8:] # display the last 7 years since 2013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "fZ1oCMUPk581",
        "outputId": "681602d2-c24f-463a-901a-083300fbc22c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Base- line</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>00</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>Previous Year % Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>77</td>\n",
              "      <td>72</td>\n",
              "      <td>67</td>\n",
              "      <td>69</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>56</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Base- line  95  96  97  98  99  00  01  02  03  ...  11  12  13  14  15  \\\n",
              "Delta         77  72  67  69  65  68  66  61  66  67  ...  56  65  68  71  71   \n",
              "\n",
              "         16    17    18    19 Previous Year % Change  \n",
              "Delta  71.0  76.0  74.0  75.0                    1.4  \n",
              "\n",
              "[1 rows x 27 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.loc[['Delta']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "MmTJJ_0Im1BS",
        "outputId": "15209a53-eac3-4ac2-a8f0-dd3d8b182f1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>00</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>04</th>\n",
              "      <th>...</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>72</td>\n",
              "      <td>67</td>\n",
              "      <td>69</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>62</td>\n",
              "      <td>56</td>\n",
              "      <td>65</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       95  96  97  98  99  00  01  02  03  04  ...  10  11  12  13  14  15  \\\n",
              "Delta  72  67  69  65  68  66  61  66  67  67  ...  62  56  65  68  71  71   \n",
              "\n",
              "         16    17    18    19  \n",
              "Delta  71.0  76.0  74.0  75.0  \n",
              "\n",
              "[1 rows x 25 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.loc[['Delta']].iloc[:, 1:-1] # exclude the first and last column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "4zT4bYfXl6c0",
        "outputId": "56881169-bfa8-4ff7-e751-6c72ee3c1979"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00</th>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01</th>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02</th>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03</th>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>04</th>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>05</th>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>06</th>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>07</th>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08</th>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09</th>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Delta\n",
              "95   72.0\n",
              "96   67.0\n",
              "97   69.0\n",
              "98   65.0\n",
              "99   68.0\n",
              "00   66.0\n",
              "01   61.0\n",
              "02   66.0\n",
              "03   67.0\n",
              "04   67.0\n",
              "05   65.0\n",
              "06   64.0\n",
              "07   59.0\n",
              "08   60.0\n",
              "09   64.0\n",
              "10   62.0\n",
              "11   56.0\n",
              "12   65.0\n",
              "13   68.0\n",
              "14   71.0\n",
              "15   71.0\n",
              "16   71.0\n",
              "17   76.0\n",
              "18   74.0\n",
              "19   75.0"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.loc[['Delta']].iloc[:, 1:-1].T.apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Z7B8jLBfpeBk",
        "outputId": "359469d5-27b2-4cd7-f702-676501cdd538"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>66.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>56.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>64.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>67.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>71.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>76.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Delta\n",
              "count  25.000\n",
              "mean   66.760\n",
              "std     4.994\n",
              "min    56.000\n",
              "25%    64.000\n",
              "50%    67.000\n",
              "75%    71.000\n",
              "max    76.000"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.loc[['Delta']].iloc[:, 1:-1].T.apply(pd.to_numeric, errors='coerce').describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4mE8sbW9IOB"
      },
      "source": [
        "We select the column \"13\" for the year when tweets were extracted (use \"23\" in case you are analyzing current tweets) and the rows related to analyzed companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8jJfNKq39IOB"
      },
      "outputs": [],
      "source": [
        "airline_names = [\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        "acsi_score = acsi_table.loc[airline_names, \"13\"].astype(float).sort_index() # loc() function let us select only certain columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg7Ug9C9IOE",
        "outputId": "b41d02ba-e9e9-4a89-d68b-4fe9cecb379f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "Name: 13, dtype: float64"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5F0584r9IOF"
      },
      "source": [
        "In case you miss the required libraries, here are two alternative instructions to create the ACSI scores series without using the `read_html` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wroivXas9IOF"
      },
      "outputs": [],
      "source": [
        "# 2023 (current_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      79.0 ,     77.0 ,      75.0 ,   79.0 ,    75.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpIwLxb39IOG",
        "outputId": "1aac9087-9ec8-4783-9258-c9d5a3130203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2013 (archive_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      81.0 ,     83.0 ,      65.0 ,   68.0 ,    62.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()\n",
        "\n",
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOIy6Cvd9IOH"
      },
      "source": [
        "We extracted a single column of the table along with the index containing company names: we change ACSI airline names in order to match the index from `twitter_scores`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-B_8edSA9IOH"
      },
      "outputs": [],
      "source": [
        "acsi_score.index = (acsi_score.index\n",
        "                    .str.lower()\n",
        "                    .str.replace(\"american\", \"americanair\")\n",
        "                    .str.replace(\"southwest\", \"southwestair\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJTUitHH9IOI",
        "outputId": "189d43ff-a0d0-498c-d4d0-ce2a1259c957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "americanair     65.0\n",
              "delta           68.0\n",
              "jetblue         83.0\n",
              "southwestair    81.0\n",
              "united          62.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDcu3Kfx9IOJ"
      },
      "source": [
        "We have now the `acsi_score` series and the `score` column of the `twitter_score` frame indexed with the same labels, but in different order: we can merge them into a new frame to align the series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hhtsXGno9IOJ",
        "outputId": "adcc9f56-967c-4cdb-9a41-330b4f6aefb0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitter</th>\n",
              "      <th>acsi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>79.195</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>67.442</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>83.333</td>\n",
              "      <td>83.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>78.205</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>53.670</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              twitter  acsi\n",
              "americanair    79.195  65.0\n",
              "delta          67.442  68.0\n",
              "jetblue        83.333  83.0\n",
              "southwestair   78.205  81.0\n",
              "united         53.670  62.0"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\"twitter\": twitter_score[\"score\"], \"acsi\": acsi_score})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZhczxte9IOK"
      },
      "source": [
        "We can now evaluate the degree of agreement between the two scores: we may do it graphically using a _scatter plot_..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "pFLxT67U9IOK",
        "outputId": "3270a5b6-69fb-489e-f3f8-e9d7aa569879"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plt.scatter() function is used to plot points. 's' parameters can be use to set the point dimension\n",
        "plt.scatter(twitter_score[\"score\"], acsi_score, s=50)\n",
        "\n",
        "# plot a x=y segment. First two parameters represents the coordinates of the segment,\n",
        "# while the third one let us draw red dashes\n",
        "plt.plot([50, 100], [50, 100], \"r--\")\n",
        "plt.xlabel(\"Twitter score\")\n",
        "plt.ylabel(\"ACSI score\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL-_tWRJ9IOL"
      },
      "source": [
        "Each point indicates the scores of a company, the dashed line indicates where scores match: the most the points are close to the line, the most the scores agree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8Q-miJ9IOM"
      },
      "source": [
        "To properly verify the agreement of the two scores (variables), we have to apply a correlation measure. There are different options.\n",
        "\n",
        "*   **Pearson Correlation** (Freedman et al., 2007), measures the X-Y linear dependence. A relationship between two variables that can be represented by a straight line. It implies that the change in one variable is proportional to the change in the other.\n",
        "*   **Spearman Correlation** (Zar, 2005), measures the X-Y monotonic relationships (whether linear or not). In other words, as one variable increases (or decreases), the other variable also consistently increases (or decreases), without any reversals or fluctuations in the trend.\n",
        "*   **Kendall’s τ** (Kendall, 1938) measures the XY ordinal association (ranking preservation).\n",
        "\n",
        "We refer to [Sai et al. (2022)](https://arxiv.org/pdf/2008.12009.pdf), page 41, for an in-depth discussion on their differences and selection criteria. In all cases, coefficients take values in [−1, 1], from low to high agreement, with 0 denoting total independence.\n",
        "\n",
        "\n",
        "We select the **Pearson's correlation coefficient**.\n",
        "It is calculated as the covariance normalized between -1 and +1:\n",
        "\n",
        "${\\displaystyle \\rho _{X,Y}={\\frac {\\operatorname {cov} (X,Y)}{\\sigma _{X}\\sigma _{Y}}}}$\n",
        "\n",
        "where\n",
        "- $\\sigma _{X}$ is the standard deviation of $X$\n",
        "- $\\sigma_Y$ is the standard deviation of $Y$\n",
        "- $\\operatorname {cov}$  is the covariance\n",
        "\n",
        "Recall that:\n",
        "- Standard deviation is the square root of the average squared distance between each data point and the mean of the dataset (_a measure of dispersion_).\n",
        "- Covariance quantifies _the degree to which two variables change together_, with a positive value indicating a tendency to increase or decrease together and a negative value indicating an inverse relationship. It is computed by taking the sum of the products of the deviations of each variable's values from their respective means, divided by the number of observations minus one.\n",
        "\n",
        "$\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}$\n",
        "\n",
        "$cov(X, Y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLMeuQd9IOM",
        "outputId": "6e5b6929-f1cc-4134-9adf-87e4e8963df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7231598735081547, 0.16740383740447337)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearson_coeff, pvalue = pearsonr(twitter_score[\"score\"], acsi_score)\n",
        "pearson_coeff, pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igRoHtv-9ION"
      },
      "source": [
        "The first value is the Pearson's coefficient, while the second value is the associated p-value, i.e. the probability that the correlation between the two series was obtained by chance.\n",
        "\n",
        "The **p-value** associated with the Pearson correlation coefficient tests the null hypothesis that there is no correlation between the two variables in the population. The p-value helps you decide whether to reject the null hypothesis. A small p-value (i.e., below a chosen significance level) indicates that the correlation is statistically significant, providing evidence against the null hypothesis of no correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1wEVYlPl1Wh"
      },
      "source": [
        "To decide if the two ACSI distributions and ours are equivalent it is necessary\n",
        "1. set a confidence level, for example $0.80$\n",
        "2. check if $pvalue < (1-0.80) = 0.20$;\n",
        "\n",
        "\n",
        "In this case pvalue is $< 0.20$ so we decide that the difference between the two distributions is the result of chance, i.e. the difference is not statistically significant, in other words they are equivalent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps1-Zgh-lkMw",
        "outputId": "9afb9fe0-bbcd-4a80-fcb6-d62cedcc75bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our distribution and the ACSI one are equivalent!\n"
          ]
        }
      ],
      "source": [
        "confidence_level = 0.80\n",
        "alpha = (1 - confidence_level)\n",
        "\n",
        "if pvalue < alpha:\n",
        "  print(\"Our distribution and the ACSI one are equivalent!\")\n",
        "else:\n",
        "  print(\"Our distribution and the ACSI one are different!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0CVCda9ION"
      },
      "source": [
        "### 👨‍💻 Exercise 1: interpreting negations\n",
        "\n",
        "In the `sentiment_score` function, when we look for positive or negative words, we do not consider whether they are negated\n",
        "\n",
        "**A)** The `sentiment_score_neg` function below implements the same logic of `sentiment_score` so that it can be more easily changed: modify it in order to count any positive word immediately preceded by \"not\" (case-insensitive) as negative and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7_ebKPt09IOP"
      },
      "outputs": [],
      "source": [
        "def sentiment_score_neg(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    score = 0\n",
        "    for i in range(len(words)):\n",
        "        word_score = 0\n",
        "\n",
        "        if i != 0 and words[i-1] in [\"not\", \"n't\", \"no\"]:\n",
        "            sign = -1\n",
        "        else: \n",
        "            sign = 1\n",
        "\n",
        "        if words[i].lower() in pos_words:\n",
        "            word_score = sign * 1\n",
        "        elif words[i].lower() in neg_words:\n",
        "            word_score = sign * -1\n",
        "        score += word_score\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eozF1o_R9IOQ"
      },
      "source": [
        "**B)** Apply the function developed in the previous point to the tweets; i.e., create a pandas series `tweet_scores_neg` (using the `sentiment_score_neg`) with all the scores of the tweets in `tweets[\"text\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       0\n",
              "3      -1\n",
              "4       0\n",
              "       ..\n",
              "4382   -4\n",
              "4383    3\n",
              "4384    3\n",
              "4385    1\n",
              "4386    0\n",
              "Name: text, Length: 4387, dtype: int64"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweet_scores_neg = pd.Series(tweets[\"text\"].apply(sentiment_score_neg, args=(airline_pos_words, airline_neg_words)))\n",
        "tweet_scores_neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYBWW05y9IOQ"
      },
      "source": [
        "**C)** Compute the mean absolute difference between this previous score and the new score of each tweet; how much the score differ from the previous \"not\"-unaware lexicon estimator?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04330977889218145"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_diff = abs(tweet_scores_neg - tweets_with_scores['score'])\n",
        "scores_diff.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8wVHZ-R9IOQ"
      },
      "source": [
        "**D)** Compute a summary score for each airline by using the `get_summary_scores` function defined in the main notebook with your novel estimator. Save the results in a pandas series termed `twitter_score_neg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "airline\n",
              "americanair     78.065\n",
              "delta           66.071\n",
              "jetblue         83.333\n",
              "southwestair    78.981\n",
              "united          52.804\n",
              "Name: text, dtype: float64"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_score_neg = pd.Series(get_summary_scores(tweet_scores_neg))\n",
        "twitter_score_neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9sRf63e9IOQ"
      },
      "source": [
        "**E)** Verify the correlation between the new Twitter score and the ACSI score using a scatter plot and Pearson's coefficient as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7576372592642269, 0.1379041856723378)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(twitter_score_neg, acsi_score, s=50)\n",
        "plt.plot([50, 100], [50, 100], \"r--\")\n",
        "\n",
        "pearson_coeff, pvalue = pearsonr(twitter_score_neg, acsi_score)\n",
        "pearson_coeff, pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygvv94X9IOQ"
      },
      "source": [
        "## Activity 2: Sentiment Analysis at sentence and feature level on hotel reviews\n",
        "\n",
        "🎯 We want to reuse the techniques seen in Activity 1 to perform sentiment analysis at sentence and feature level on hotel reviews\n",
        "\n",
        "TripAdvisor used to provide a summary of hotel ratings against 6 different features: **Location, Sleep Quality, Rooms, Service, Value, Cleanliness**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwNfCgBU9IOR"
      },
      "source": [
        "### Activity plan\n",
        "\n",
        "1. Define lists of opinion and feature words\n",
        "  - For opinion words, we reuse the lists of Hu and Liu from Activity 1\n",
        "2. Break reviews into sentences\n",
        "3. Detect sentences dealing with a specific feature and score its sentiment\n",
        "4. Summarize evaluation of each hotel and each feature\n",
        "5. Compare features of each hotel\n",
        "6. Compare results with scores on TripAdvisor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf0Kw1v49IOR"
      },
      "source": [
        "### Load reviews\n",
        "\n",
        "We provide a ZIP file with reviews of 6 different Hotels in Chicago, in a format similar to that of airline tweets used above (one file per hotel, one review per line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kOhA6CRF9IOR"
      },
      "outputs": [],
      "source": [
        "download(\"hotel-reviews.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/hotel-reviews.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMYKO7r39IOT",
        "outputId": "9f79f8a8-d978-4a37-b8db-fa4caa6692cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usa_illinois_chicago_affinia_chicago.txt\n",
            "affinia_chicago\n",
            "usa_illinois_chicago_hyatt_regency_chicago.txt\n",
            "hyatt_regency_chicago\n",
            "usa_illinois_chicago_intercontinental_chicago.txt\n",
            "intercontinental_chicago\n",
            "usa_illinois_chicago_james_chicago.txt\n",
            "james_chicago\n",
            "usa_illinois_chicago_swissotel_chicago.txt\n",
            "swissotel_chicago\n",
            "usa_illinois_chicago_the_palmer_house_hilton.txt\n",
            "the_palmer_house_hilton\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "import re\n",
        "\n",
        "all_reviews = {} # Init an empty dictionary that will be used to collect all the reviews\n",
        "\n",
        "# Define the regular expression that matches the reviews filenames\n",
        "filename_pattern = re.compile(\"usa_illinois_chicago_([a-z_]+).txt\") # ([a-z_]+) means: \"one or more groups of alphabetic characters followed by an underscore\"\n",
        "\n",
        "with ZipFile(\"hotel-reviews.zip\") as zip: # open the zip file and read the files inside\n",
        "\n",
        "    for filename in zip.namelist(): # we repeat the following statements for each file inside the zip in order to collect the text of each hotel; 1 file --> 1 hotel\n",
        "\n",
        "        print(filename)\n",
        "\n",
        "        # match() returns a match object if one or more characters at the beginning of string match our regular expression, None otherwise\n",
        "        # Then we call the group() method on the match object: group(1) returns the matched content of the first parenthesized subgroup in the regular expression\n",
        "        hotel = filename_pattern.match(filename).group(1)\n",
        "\n",
        "        print(hotel)\n",
        "\n",
        "        with zip.open(filename) as f: # open each txt file to read its content (i.e the reviews texts)\n",
        "\n",
        "            # for each file: decode each line of the file to UTF-8 encoding (to properly read the string), delete spaces at beginning/end of the string using strip()\n",
        "            # put each transformed line in a list using list()\n",
        "            # put the list of lines of the current file in a new entry of all_reviews dictionary\n",
        "            all_reviews[hotel] = list(line.decode(errors=\"ignore\").strip() for line in f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGIOvin9IOU"
      },
      "source": [
        "As an example, we will use reviews for the Intercontinental hotel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DjuPCyyq9IOV"
      },
      "outputs": [],
      "source": [
        "reviews_interc = all_reviews[\"intercontinental_chicago\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WHYJMRsK9IOX",
        "outputId": "a528c2f6-ea8a-444f-ce15-8295feeaefe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A great spot! We have always been pleased with our stays at Intercontinental hotels. Chicago was especially pleasant with a helpful staff.'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews_interc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbemiaFE9IOY"
      },
      "source": [
        "### Lists of feature words\n",
        "\n",
        "We need feature-related keywords to detect sentences dealing with a specific feature of our interest\n",
        "\n",
        "Using only the names of the 6 features as keywords, would produce few results\n",
        "\n",
        "The lists within _feature words_ (manually created, in this case) provide synonyms or terms related to each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "S-3DBtSl9IOZ"
      },
      "outputs": [],
      "source": [
        "feature_words = {\n",
        "    'location': {'location', 'airport', 'center', 'island', 'lake', 'ocean',\n",
        "                 'sea', 'around', 'university', 'romantic', 'coast', 'beach',\n",
        "                 'disco', 'nightlife'},\n",
        "    'sleepquality': {'silence','sleep','night','noise','nightlife'},\n",
        "    'rooms': {'room', 'rooms', 'space', 'bed', 'bath', 'bathroom', 'toilet',\n",
        "              'degrade', 'disorder','shower','jacuzzi','frigo'},\n",
        "    'service': {'service','pet','friendly','swimming', 'pool', 'pools', 'spa',\n",
        "                'waiters', 'severs', 'waiter', 'manservant', 'cordial',\n",
        "                'hearty', 'restorative', 'disagreeable', 'unpleasant',\n",
        "                'restaurant', 'food', 'breakfast', 'lunch', 'dinner', 'bar'},\n",
        "    'value': {'cheap','affordable','afford','woth', 'price', 'value', 'cost',\n",
        "              'expensive', 'economical', 'depreciate', 'discount', 'luxury',\n",
        "              'hall', 'meal'},\n",
        "    'cleanliness': {'clean', 'cleanliness', 'place', 'neatness', 'sweeping',\n",
        "                    'dirty', 'soiled', 'grubby', 'foul', 'mucky'}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3tsTGX9IOa"
      },
      "source": [
        "### Breaking reviews into sentences\n",
        "\n",
        "We break reviews into single sentences, assuming that each sentence deals with (at most) one of the features\n",
        "\n",
        "Breaking text into sentences (_sentence tokenization_) is not straightforward: sentences usually end with a period (\".\"), but may also end with other punctuation (\"!\", \"?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGtjlvH9IOa"
      },
      "source": [
        "This is an example of function for sentence tokenization, which splits text on \".\", \"?\" and \"!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "GtYfbWuB9IOa"
      },
      "outputs": [],
      "source": [
        "def my_sent_tokenizer(text):\n",
        "    return re.split(\"[\\\\.\\\\?!]\", text) #\\\\ operator escapes the dot and question mark characters. This is needed because '.' and '?' are special characters in regex syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-qawU1O9IOb",
        "outputId": "47715e19-2851-46d4-f5e0-45234f238deb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A great spot',\n",
              " ' We have always been pleased with our stays at Intercontinental hotels',\n",
              " ' Chicago was especially pleasant with a helpful staff',\n",
              " '']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_sent_tokenizer(reviews_interc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsr537m99IOe"
      },
      "source": [
        "However, this function fails when these characters are used in the middle of a sentence, e.g. in an ellipsis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwOjGfT9IOe",
        "outputId": "408bebac-71a5-4db2-9edc-b7ef29f6ed15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This works', '', '', ' or not', ' Maybe not', '']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_sent_tokenizer(\"This works... or not? Maybe not.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGF6ez9s9IOf"
      },
      "source": [
        "Similarly to the word tokenizer used above, NLTK provides a sentence tokenizer based on knowledge of English language to detect such exceptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urU6hiB9IOg",
        "outputId": "810958a2-9b6a-44b8-9103-a782fdafe671"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This works... or not?', 'Maybe not.']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.sent_tokenize(\"This works... or not? Maybe not.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFIWabkV9IOh"
      },
      "source": [
        "Using this tokenization function, we turn the list of reviews into a list of single sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Hz-aaqP39IOh"
      },
      "outputs": [],
      "source": [
        "sentences_interc = [sent for review in reviews_interc for sent in nltk.sent_tokenize(review)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWUuSZu49IOi"
      },
      "source": [
        "### Detecting features and opinions in sentences\n",
        "\n",
        "We define a function which counts, for each feature, the number of sentences in a given list expressing a positive or negative judgement about it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "1Qxb70Fj9IOi"
      },
      "outputs": [],
      "source": [
        "def feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words):\n",
        "\n",
        "    # initialize to 0 counts of positive and negative sentences per feature\n",
        "    pos_counts = {feat: 0 for feat in feature_words.keys()}\n",
        "    neg_counts = {feat: 0 for feat in feature_words.keys()}\n",
        "    # {\n",
        "    #  \"location\": 0,\n",
        "    #  \"service\": 0,\n",
        "    #  ...\n",
        "    # }\n",
        "\n",
        "    for sent in sentences: # analyze each sentence in the sentences list passed as argument to this function\n",
        "\n",
        "        # evaluate the sentiment of the current sentence\n",
        "        word_list = nltk.word_tokenize(sent) # e.g. nltk.word_tokenize(\"This isn't a test, or is it?\") --> ['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']\n",
        "        pos_word_count = sum(1 for word in word_list if word in pos_words) # Sum 1 for each positive word found in the sentence. E.g. 2\n",
        "        neg_word_count = sum(1 for word in word_list if word in neg_words) # Sum 1 for each negative word found in the sentence. E.g. 3\n",
        "        sent_score = pos_word_count - neg_word_count # E.g. 2 - 3 = -1\n",
        "\n",
        "        # detect features in sentence\n",
        "        word_set = set(word_list) # e.g. {'this', 'is', \"n't\", \"a\", \"test\", \",\", \"or\", \"it\", \"?\"}   No words are repeated since we use a set!\n",
        "        # loop over each feature (e.g. value, service, ...) to analyze features in the current sentence\n",
        "        # (i.e. the variable named 'sent')\n",
        "        for feat, keywords in feature_words.items():\n",
        "            # if the intersection between the sentence word set and the feature keywords is not empty\n",
        "            # (i.e. the sentence contains at least one of the current feature keywords)\n",
        "            if word_set & keywords:\n",
        "                if sent_score > 0: # if the sentence polarity is positive\n",
        "                    pos_counts[feat] += 1 # increment by one the positive counter of the current feature we are analyzing\n",
        "                elif sent_score < 0: # if the sentence polarity is negative\n",
        "                    neg_counts[feat] += 1 # increment by one the negative counter of the current feature we are analyzing\n",
        "\n",
        "    # At the end of the positive/negative counts for each feature, we create a new dataframe containing the features\n",
        "    # as rows and the two counters as columns\n",
        "    return pd.DataFrame({\"pos_count\": pos_counts, \"neg_count\": neg_counts})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmR31Yb9IOj"
      },
      "source": [
        "For each list of sentences, the function returns a DataFrame with counts of positive and negative sentences for each feature\n",
        "\n",
        "Let's apply it for example to reviews of Intercontinental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Sl6kJjaF9IOk"
      },
      "outputs": [],
      "source": [
        "scores_interc = feature_pos_neg_counts(sentences_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ODajRR8-9IOk",
        "outputId": "cd22a8b2-461a-44a8-c715-8bf434be1773"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>230</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>49</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>372</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>130</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count\n",
              "location            230         18\n",
              "sleepquality         49         28\n",
              "rooms               423         92\n",
              "service             372         55\n",
              "value                70         34\n",
              "cleanliness         130         11"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_interc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5smNWpx9IOl"
      },
      "source": [
        "### Summarizing evaluation of hotel features\n",
        "\n",
        "Similarly to above, we compute for each feature a sentiment score in a 0-50 scale from the ratio of positive sentences about a feature w.r.t. their total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "hvyHtRYs9IOm"
      },
      "outputs": [],
      "source": [
        "scores_interc[\"tot_count\"] = scores_interc.pos_count + scores_interc.neg_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "NxSaH52X9IOn"
      },
      "outputs": [],
      "source": [
        "scores_interc[\"score\"] = round(50 * scores_interc.pos_count / scores_interc.tot_count) # we divide the percentage by 2 since we deal with 0-5 stars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "TPqAtJN99IOo",
        "outputId": "7eafe300-ad0b-4c09-d1d9-29386e0caf8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "      <th>tot_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>230</td>\n",
              "      <td>18</td>\n",
              "      <td>248</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>49</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "      <td>515</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>372</td>\n",
              "      <td>55</td>\n",
              "      <td>427</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>104</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>130</td>\n",
              "      <td>11</td>\n",
              "      <td>141</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count  tot_count  score\n",
              "location            230         18        248   46.0\n",
              "sleepquality         49         28         77   32.0\n",
              "rooms               423         92        515   41.0\n",
              "service             372         55        427   44.0\n",
              "value                70         34        104   34.0\n",
              "cleanliness         130         11        141   46.0"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_interc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCoak-S39IOp"
      },
      "source": [
        "In order to easily repeat this process for every hotel, we wrap it in a function which takes as input the list of reviews and returns the Series with the final scores per feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "xL4QJitL9IOp"
      },
      "outputs": [],
      "source": [
        "def feature_scores(reviews, feature_words, pos_words, neg_words):\n",
        "    sentences = [sent for review in reviews for sent in nltk.sent_tokenize(review)]\n",
        "    counts = feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words)\n",
        "    total = counts.pos_count + counts.neg_count\n",
        "    return round(50 * counts.pos_count / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF2X1PJN9IOq",
        "outputId": "46d382cf-997d-454e-b4b1-37e8fb06165b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "location        46.0\n",
              "sleepquality    32.0\n",
              "rooms           41.0\n",
              "service         44.0\n",
              "value           34.0\n",
              "cleanliness     46.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_scores(reviews_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovCL19qT9IOr"
      },
      "source": [
        "Let's create a DataFrame with feature scores for all analyzed hotels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "RnPw_fR_9IOr"
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame({hotel: feature_scores(reviews, feature_words, hu_liu_pos, hu_liu_neg) for hotel, reviews in all_reviews.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "eZMYfs7G9IOs",
        "outputId": "b407b4c8-bc42-45db-bc7a-9378e61765a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              affinia_chicago  hyatt_regency_chicago  \\\n",
            "location                 45.0                   45.0   \n",
            "sleepquality             25.0                   27.0   \n",
            "rooms                    42.0                   37.0   \n",
            "service                  45.0                   39.0   \n",
            "value                    39.0                   30.0   \n",
            "cleanliness              46.0                   42.0   \n",
            "\n",
            "              intercontinental_chicago  james_chicago  swissotel_chicago  \\\n",
            "location                          46.0           47.0               44.0   \n",
            "sleepquality                      32.0           30.0               32.0   \n",
            "rooms                             41.0           41.0               40.0   \n",
            "service                           44.0           44.0               43.0   \n",
            "value                             34.0           35.0               34.0   \n",
            "cleanliness                       46.0           46.0               46.0   \n",
            "\n",
            "              the_palmer_house_hilton  \n",
            "location                         45.0  \n",
            "sleepquality                     26.0  \n",
            "rooms                            37.0  \n",
            "service                          40.0  \n",
            "value                            35.0  \n",
            "cleanliness                      44.0  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>sleepquality</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>cleanliness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>affinia_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hyatt_regency_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intercontinental_chicago</th>\n",
              "      <td>46.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>james_chicago</th>\n",
              "      <td>47.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swissotel_chicago</th>\n",
              "      <td>44.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the_palmer_house_hilton</th>\n",
              "      <td>45.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          location  sleepquality  rooms  service  value  \\\n",
              "affinia_chicago               45.0          25.0   42.0     45.0   39.0   \n",
              "hyatt_regency_chicago         45.0          27.0   37.0     39.0   30.0   \n",
              "intercontinental_chicago      46.0          32.0   41.0     44.0   34.0   \n",
              "james_chicago                 47.0          30.0   41.0     44.0   35.0   \n",
              "swissotel_chicago             44.0          32.0   40.0     43.0   34.0   \n",
              "the_palmer_house_hilton       45.0          26.0   37.0     40.0   35.0   \n",
              "\n",
              "                          cleanliness  \n",
              "affinia_chicago                  46.0  \n",
              "hyatt_regency_chicago            42.0  \n",
              "intercontinental_chicago         46.0  \n",
              "james_chicago                    46.0  \n",
              "swissotel_chicago                46.0  \n",
              "the_palmer_house_hilton          44.0  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(scores)\n",
        "\n",
        "scores.T   # transpose the table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRg2vywT9IOv"
      },
      "source": [
        "We can create a bar plot to compare the hotels by each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "Z77JJX999IOv",
        "outputId": "ed89eb52-2f04-4a07-a8a6-1c3edf8042f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scores.plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr17VRMp9IOw"
      },
      "source": [
        "### Comparing scores with TripAdvisor\n",
        "\n",
        "Obtained scores can be compared with the feature ratings which were computed by TripAdvisor up to some time ago\n",
        "\n",
        "For example, give a look at the room scores. From our analysis, Hyatt and Palmer are among those with the lowest values. Is it true?\n",
        "\n",
        "\n",
        "![hotel ratings](https://www.dropbox.com/s/pq6q9ugsaessow6/hotel-ratings.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k9gENE_9IOw"
      },
      "source": [
        "## Activity 3: Classification of Movie Reviews via Supervised Training\n",
        "\n",
        "🎯 We want to classify user reviews of movies extracted from IMDB as positive or negative\n",
        "\n",
        "Contrarily to previous activities, this time **we will train a classificaton model on existing reviews instead of using manually set keywords**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXWxfW1Q9IOw"
      },
      "source": [
        "### Load reviews\n",
        "\n",
        "We load reviews from a GZIP-compressed CSV file of 10,000 movie reviews, alternated between positive and negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "gyb5edlH9IOx"
      },
      "outputs": [],
      "source": [
        "download(\"acl-10k.csv.gz\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/acl-10k.csv.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "pUWkUCnB9IOy"
      },
      "outputs": [],
      "source": [
        "reviews = pd.read_csv(\"acl-10k.csv.gz\", sep=\"\\t\", header=None, names=[\"label\", \"text\"], compression=\"gzip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gYE_BFzX9IOz",
        "outputId": "55d8b38c-4706-47f9-c7d2-2de77143d1be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   pos   \n",
              "1   neg   \n",
              "2   pos   \n",
              "3   neg   \n",
              "4   pos   \n",
              "\n",
              "                                                                                                  text  \n",
              "0  Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...  \n",
              "1  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...  \n",
              "2  If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...  \n",
              "3  Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...  \n",
              "4  Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U172DUlL9IO0"
      },
      "source": [
        "In order to validate the goodness of automated classification, we use the _hold-out_ approach: a part of the reviews is used to train a classifier, while the remaining ones are used to assess its accuracy\n",
        "\n",
        "Let's select the first half of the reviews as the _training set_ and the second half as the _test set_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "KxsrEToT9IO0"
      },
      "outputs": [],
      "source": [
        "reviews_train = reviews[:5000] # first 5000 reviews\n",
        "reviews_test = reviews[5000:] # last 5000 reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSndGPba9IO1"
      },
      "source": [
        "### Bag of Words and Vector Space Model\n",
        "\n",
        "In order to train and use a classifier on reviews, we have to define the _features_ which represent them\n",
        "\n",
        "With the _Bag of Words_ model we represent each review as the set of words contained in it, regardless of their order\n",
        "\n",
        "Once defined a set of known words, we can represent each review with a vector indicating for each word the number of occurrencies in the text; **a set of reviews can be be consequently represented as a _document-term matrix_ with a row vector for each review**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Wvi4Uo9IO1"
      },
      "source": [
        "Let's define a list of example text documents..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "CV26ZAf49IO1"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"the sky is blue\",\n",
        "    \"sky is blue and sky is beautiful\",\n",
        "    \"the beautiful sky is so blue\",\n",
        "    \"i love blue cheese\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MossE1cR9IO2"
      },
      "source": [
        "A `CountVectorizer` extracts a vector for each document with counts of distinct words in it: we start from creating an \"empty\" vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WeRiIqIZ9IO2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abjwprh_9IO3"
      },
      "source": [
        "We use the `fit_transform` method passing the list of documents to\n",
        "\n",
        "- \"build\" the vector space with dimensions corresponding to words within them (_fit_)\n",
        "- return the document-term matrix representing them (_transform_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaqE_cGv9IO3",
        "outputId": "56d506ee-97a7-4fb6-dee8-7eb8e36a4822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtm = vect.fit_transform(docs)\n",
        "dtm # 4 x 9 matrix, 4 rows represent the number of documents, 9 columns represent the number of distinct words found within them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNyRpX6J9IO4"
      },
      "source": [
        "The obtained `dtm` matrix contains a row for each document and a column for each distinct word found within documents: we can obtain a list of the words \"learned\" by the vectorizer..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsirTqtE9IO4",
        "outputId": "f9b9edb9-c2c0-4cea-e1e0-5b74460c0c7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so',\n",
              "       'the'], dtype=object)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vDbPWyr9IO5"
      },
      "source": [
        "Let's view the matrix as a DataFrame, labeling rows and columns with corresponding documents and features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "C8xOa6zB9IO5",
        "outputId": "45830b37-4419-4c2a-c0ad-c0fda075bc9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  and  beautiful  blue  cheese  is  love  sky  \\\n",
              "the sky is blue                     0          0     1       0   1     0    1   \n",
              "sky is blue and sky is beautiful    1          1     1       0   2     0    2   \n",
              "the beautiful sky is so blue        0          1     1       0   1     0    1   \n",
              "i love blue cheese                  0          0     1       1   0     1    0   \n",
              "\n",
              "                                  so  the  \n",
              "the sky is blue                    0    1  \n",
              "sky is blue and sky is beautiful   0    0  \n",
              "the beautiful sky is so blue       1    1  \n",
              "i love blue cheese                 0    0  "
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoJFPERf9IO6"
      },
      "source": [
        "As we can see, the matrix indicates for each document the number of occurrencies of each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRH85pEK9IO6"
      },
      "source": [
        "Using the `transform` method, we can represent further documents in the same vector space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "MNvHGGTU9IO6"
      },
      "outputs": [],
      "source": [
        "new_docs = [\"loving this blue sky today\"]\n",
        "new_dtm = vect.transform(new_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "k3ZWv5yl9IO7",
        "outputId": "1092f8fb-1454-4537-e1e2-714f27b539a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>loving this blue sky today</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            and  beautiful  blue  cheese  is  love  sky  so  \\\n",
              "loving this blue sky today    0          0     1       0   0     0    1   0   \n",
              "\n",
              "                            the  \n",
              "loving this blue sky today    0  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(new_dtm.toarray(), index=new_docs, columns=vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdXF5wcL9IO-"
      },
      "source": [
        "Notice that some words of the new document (e.g. \"loving\") are lost in the representation, because they are not known in the vector space, but this is generally a minor problem if the vector space is built on many documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEB3lHRu9IO_"
      },
      "source": [
        "### Training a classifier\n",
        "\n",
        "We use the vector space model to represent reviews passed to a classifier: let's create a new vector space..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "AaeFZphn9IPA"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxVsu06v9IPB"
      },
      "source": [
        "...and fit it to reviews of the training set only (as we assume to _not_ know in advance documents of the test set), obtaining the document-term matrix representing them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "IJ19rE7L9IPB"
      },
      "outputs": [],
      "source": [
        "dtm_train = vect.fit_transform(reviews_train.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHsj5Jh9IPC"
      },
      "source": [
        "We can get the total count of extracted feature words..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUqEZwSn9IPC",
        "outputId": "693588b5-dfa9-42f0-e66b-a9f8867d149b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9puiLl9IPD"
      },
      "source": [
        "...and see some of them (they are in alphabetical order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8nvNkQL9IPD",
        "outputId": "e4ce9a83-882e-4529-9ccc-87d286e2c1ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['affections', 'affects', 'afficinados', 'affiliated',\n",
              "       'affiliation'], dtype=object)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.get_feature_names_out()[1000:1005]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbpXAp49IPE"
      },
      "source": [
        "The document-term matrix is _sparse_, meaning that most of its elements are zero. We can verify the ratio of non-zero elements by converting them to booleans and computing the mean value (all non-zero values become 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ4TYTLb9IPE",
        "outputId": "2e79a64d-6f19-4f38-fe15-1ed9322f9e5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0037657973092192322"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtm_train.astype(bool).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-5Ij_zz9IPF"
      },
      "source": [
        "Such matrix is represented in memory with a space-efficient data structure which explicitly stores non-zero values only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MtpO5hF9IPF"
      },
      "source": [
        "Now we can train any classification model on the generated vectors: let's use for example logistic regression, SVM and some bayesian models.\n",
        "\n",
        "As for the vectorizer, we first create the \"empty\" model..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FPQwg8ZD1NJ"
      },
      "source": [
        "**Bayesian model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "UV3gt-5wxKxW"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB() # Naive Bayes classifier for multinomial models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDV_JuKf-ieE"
      },
      "source": [
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Hd6GUeZ6yEno"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB # Naive Bayes classifier for multivariate Bernoulli models\n",
        "\n",
        "# The default parameter named \"binarize\" will transform each input vector in a\n",
        "# binary vector based on the specified threshold (0.0)\n",
        "model = BernoulliNB(binarize=0.0) # if input > 0.0 then 1 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyakhXB4z-v"
      },
      "source": [
        "Like MultinomialNB, this classifier is suitable for discrete data but it usually works better with few features and **short docs**.\n",
        "Indeed, this latter Naive Bayes model will perform better (Accuracy: $\\approx$ 77% vs $\\approx$ 81%) than the multinomial version since we are dealing with short texts.\n",
        "\n",
        "The difference is that while MultinomialNB works better with occurrence counts, BernoulliNB is designed for binary/boolean features! Since we have the frequency count for each term, we have to convert it into a binary variable but the BernoulliNB implementation already do this mapping!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayt1OSz2D61X"
      },
      "source": [
        "**SVM model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "0rNKFlWZ09Ko"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC() # default kernel is set to RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "2dY6AnK61uJ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model = LinearSVC(max_iter = 5000) # max_iter param represents the maximum number of iterations performed by the optimization algorithm used to train the model by the sklearn library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCAZu2v4C1L"
      },
      "source": [
        "SVM generally does just as well on textual data without using kernels because the multidimensional space is so vast that the probability of finding a separation hyperplane is similar to that of finding a nonlinear separation.\n",
        "In other words you can notice that with or without a kernel the result does not change significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSnn0LgDEA-E"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_lVIQnAS-A"
      },
      "source": [
        "Let's go on creating a logistic regression model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "1jtFH7fT9IPF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver=\"liblinear\") # liblinear is an optimization algorithm recommended for small volume (small number of rows) and high dimension (high number of columns) datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8die02Q9IPH"
      },
      "source": [
        "...then we fit it to the training set, passing the vector representation of the reviews along with their actual labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4yda-8J79IPH",
        "outputId": "d16b3ef8-0045-45f2-c1ea-10a6b4b0d8cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dtm_train, reviews_train.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TiT04TP9IPI"
      },
      "source": [
        "### Using the classifier\n",
        "\n",
        "Once the classifier is trained, we can use it to estimate labels for further reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "quyMXP829IPI"
      },
      "outputs": [],
      "source": [
        "new_reviews = [\"What an awesome movie!\", \"It was really boring\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN_eCM4V9IPI"
      },
      "source": [
        "We first have to use the vectorizer to extract their representation in the vector space..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "TImYsSgC9IPJ"
      },
      "outputs": [],
      "source": [
        "dtm_new = vect.transform(new_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1JhS_eH9IPJ"
      },
      "source": [
        "...then we use the `predict` method of the model to get corresponding predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH3B9x-A9IPJ",
        "outputId": "708b6246-5a59-4d66-90e7-e0d4728bd4f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(dtm_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XAeXqW9IPK"
      },
      "source": [
        "### Evaluating the classifier\n",
        "\n",
        "We can evaluate the goodness of the classifier by getting predicted labels for reviews in the test set and comparing them with known actual labels\n",
        "\n",
        "Given data and actual labels of the test set, the `score` method of the model computes the _accuracy_ as the ratio of test reviews for which classification is correct\n",
        "\n",
        "We first obtain the document-term matrix for the test set..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "5t3vPmrv9IPK"
      },
      "outputs": [],
      "source": [
        "dtm_test = vect.transform(reviews_test.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p-rRVcK9IPM"
      },
      "source": [
        "...then we call the `score` method on it and on the known labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGulqIl9IPM",
        "outputId": "22209f3e-2d8f-49d3-d888-4dfe286a1a22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8188"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(dtm_test, reviews_test.label) # classification accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rSJPrJY9IPN"
      },
      "source": [
        "### Creating a pipeline\n",
        "\n",
        "In all the operations above (training, predicting, evaluating) we had to manually convert text reviews into their vector representations before passing them to the model\n",
        "\n",
        "scikit-learn allows to create _pipelines_, which combine a prediction model with a sequence of one or more pre-processing steps into a single object\n",
        "\n",
        "We first create the pipeline by specifying its components, in this case the vectorizer and the actual classifier; each component has a name, allowing it to be referenced after creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "vGRxjDKU9IPO"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "model = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()), # Step 1\n",
        "    (\"classifier\", LogisticRegression(max_iter=500)) # Step 2\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS6yzG6m9IPO"
      },
      "source": [
        "Now, we can use the pipeline as we used the model above, but passing directly the text of reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "WXol6wfi9IPP"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);\n",
        "# \";\" is used to suppress output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9h8m8L9IPP",
        "outputId": "8f6e522d-fd04-4086-fe95-89c99aaa0736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(new_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EYlXN3g9IPQ",
        "outputId": "393c8c62-5063-444e-b3c7-355925ef0cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8194"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8flQBB9IPS"
      },
      "source": [
        "We obtain the same result as above, but with cleaner code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s0lFHW9IPS"
      },
      "source": [
        "### Applying tf.idf term weighting\n",
        "\n",
        "The `CountVectorizer` generates vectors with simple counts of occurrencies of terms within a document, without considering the relative importance of such terms with respect to each other\n",
        "\n",
        "The _tf.idf_ term weighting scheme uses a formula with two factors to better evaluate the weight of each term in each document\n",
        "\n",
        "- The _tf_ factor evaluates the _local_ importance of a term in a document: it is usually the count of term occurrencies (or its logarithm)\n",
        "- The _idf_ factor evaluates the _global_ importance of a term in the set of documents: it is higher for terms appearing in fewer documents, as they are supposed to be more specific\n",
        "\n",
        "$\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)$\n",
        "\n",
        "\n",
        "In order to use tf.idf in place of raw counts of occurrencies, we simply use `TfidfVectorizer` in place of `CountVectorizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTWh-mql9IPS"
      },
      "source": [
        "Let's see for example the tf.idf applied to example documents used above..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "1adRlwwO9IPS",
        "outputId": "15681148-7615-448b-db0b-b7af059e43ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.399</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    and  beautiful   blue  cheese     is  \\\n",
              "the sky is blue                   0.000      0.000  0.399   0.000  0.488   \n",
              "sky is blue and sky is beautiful  0.441      0.347  0.230   0.000  0.562   \n",
              "the beautiful sky is so blue      0.000      0.432  0.286   0.000  0.350   \n",
              "i love blue cheese                0.000      0.000  0.346   0.663  0.000   \n",
              "\n",
              "                                   love    sky     so    the  \n",
              "the sky is blue                   0.000  0.488  0.000  0.603  \n",
              "sky is blue and sky is beautiful  0.000  0.562  0.000  0.000  \n",
              "the beautiful sky is so blue      0.000  0.350  0.548  0.432  \n",
              "i love blue cheese                0.663  0.000  0.000  0.000  "
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer()\n",
        "dtm = vect.fit_transform(docs)\n",
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TC1RFxK9IPU"
      },
      "source": [
        "We can see e.g. in the last document that \"cheese\" has an higher importance than \"blue\", being a less common and thus more discriminating word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DC0EG49IPU"
      },
      "source": [
        "We employ tf.idf in our classification pipeline by replacing `CountVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ByQMYMeM9IPU"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C2jNFgP9IPW"
      },
      "source": [
        "As above, we fit the model on the training set and then evaluate it on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "GmSW_6aS9IPW"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrIM5UFU9IPX",
        "outputId": "54410219-7bd9-4cda-e215-5e2d69ebdf2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8412"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRfG6tH99IPY"
      },
      "source": [
        "### Looking for the most influential words\n",
        "\n",
        "Logistic regression computes the likelihood of a review being positive (or negative) according to the following formula:\n",
        "$$ h_\\theta(\\mathbf{x})=\\frac{1}{1+\\exp\\left(-\\theta_0-\\sum_{i=1}^n{\\theta_i\\cdot x_i}\\right)} $$\n",
        "\n",
        "Every $x_i$ variable indicates the element $i$ of an input vector (i.e. the weight of the $i$-th word in the dictionary), while $\\theta_i$ is the model parameter indicating how much the word contributes to the review being estimated as positive or negative\n",
        "\n",
        "By looking at values of the parameters, we can find out which words contribute the most at the reviews being labeled as positive or negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e7YGzS49IPZ"
      },
      "source": [
        "The $\\theta_i$ parameters are available as the `coef_` attribute of the `LogisticRegression` model, we get it from the pipeline and print some values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbbzwNtK9IPZ",
        "outputId": "0d65b6d0-5b20-4113-bd15-24b4e4d6532d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.05077333, -0.01748804, -0.02547062,  0.04603734])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "\n",
        "model_classifier.coef_[0, :4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUAtgdBA9IPa"
      },
      "source": [
        "In order to make sense of the values, we get from the `TfidfVectorizer` the names of features and match them to values using a series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "yPsPGgMQ9IPa"
      },
      "outputs": [],
      "source": [
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXPsMfL_9IPb"
      },
      "source": [
        "We sort the values in ascending order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "2EiVr4aC9IPc"
      },
      "outputs": [],
      "source": [
        "model_coefs.sort_values(inplace=True) # inplace=True let us sort the original pandas Series stored in model_coefs variable. Otherwise sort_values would return a copy of the sorted series without sorting the original one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLV2Y5O9IPc"
      },
      "source": [
        "Now at the top of the series we find the terms with the lowest coefficients, which make the model decision most tend to the \"negative\" class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ZpIVzE9IPd",
        "outputId": "f3b91ac9-b8c5-4a2c-ab8f-e2f12f97f0d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bad      -5.166\n",
              "worst    -4.133\n",
              "awful    -2.811\n",
              "waste    -2.784\n",
              "boring   -2.772\n",
              "dtype: float64"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idX8RZY09IPe"
      },
      "source": [
        "...while at the bottom of the series we find terms with the highest coefficients, whose presence makes the review positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ThCVy2X9IPe",
        "outputId": "217e2e82-37e5-42e9-9897-b9e731f1bea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "and      2.457\n",
              "well     2.527\n",
              "love     2.676\n",
              "best     3.225\n",
              "great    4.513\n",
              "dtype: float64"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeg3twi49IPf"
      },
      "source": [
        "In this way, we can generally find out the most important terms in deciding the orientation of a review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pULaHu9z9IPf"
      },
      "source": [
        "### Regularization of parameters\n",
        "\n",
        "The logistic regression model uses _regularization_ to prevent parameters from having very high absolute values, which may lead to overfitting\n",
        "\n",
        "The C parameter controls the regularization strength: smaller values lead to stronger regularization, while larger values make the model fit more to training data\n",
        "\n",
        "This parameter can be tuned to improve the model accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78n6wGbC9IPg"
      },
      "source": [
        "Let's try for example to raise the C parameter from its default value 1 to 10, thus lowering the regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "flxU_m1R9IPg"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression(C=10))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "qNlSMPQt9IPh"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQNnmdaj9IPh",
        "outputId": "d8b933df-4f2d-4b39-96c6-67c708ba19e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8296"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLEJs_79IPi"
      },
      "source": [
        "In this case accuracy slightly drops, possibly due to overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a-QgZt9IPi"
      },
      "source": [
        "If we check for model parameters, their absolute value are now higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "2613CtoE9IPi"
      },
      "outputs": [],
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names_out())\n",
        "model_coefs.sort_values(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Qb8jwP9IPk",
        "outputId": "5e4461b4-a39d-4855-ab77-7053968b975e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "worst   -9.831\n",
              "bad     -9.659\n",
              "awful   -6.869\n",
              "dtype: float64"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1bH_gF9IPl",
        "outputId": "b1abf77c-9df0-4755-8eae-7721ffbbbd5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "perfect    6.302\n",
              "best       7.523\n",
              "great      8.939\n",
              "dtype: float64"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-9mDJ7Z9IPm"
      },
      "source": [
        "### Reducing the dimensionality (only characteristic words)\n",
        "\n",
        "Considering the number of distinct terms across all training reviews, the dimensionality of the vector space is very high"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBGZBkZE9IPm",
        "outputId": "0f6d2d00-5aca-47cc-8bbd-5dd0a12f12d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdnbUD69IPm"
      },
      "source": [
        "Methods exist to reduce the dimensionality in order to reduce the time required for training the model with very little impact on its accuracy\n",
        "\n",
        "One possibility is to not consider words appearing only in very few reviews, such as very specific terms or misspelled words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6EMtre29IPn"
      },
      "source": [
        "We can configure the vectorizer with the `min_df` parameter to exclude terms appearing e.g. in less than 3 training reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "z6ZuZ4H-9IPn"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3)), # df stands for document frequency. Keep words with 3 or more in score\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlU4nBov9IPo"
      },
      "source": [
        "Let's fit the model as above..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ujhE7B9IPo"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGd227X9IPo"
      },
      "source": [
        "Looking at the fit vectorizer, the number of dimensions is now much lower..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koXs4jxM9IPp",
        "outputId": "6e3ffb9c-d781-4b5c-cd0b-87322ce42f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16127"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d-ti6q79IPp"
      },
      "source": [
        "...but the accuracy is close to the previous value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R5wO9wf9IPq",
        "outputId": "587fe02c-5812-44b3-d0db-90ac20c8e0f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8424"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDT9_dtm9IPq"
      },
      "source": [
        "### Reducing the dimensionality (stemming)\n",
        "\n",
        "Another way to reduce dimensionality is to group similar terms into an unique feature\n",
        "\n",
        "_Stemming_ is the extraction of the morphological root (_stem_) of a word: using stems of words as features in place of words themselves, we obtain a single feature for possibly several single terms with a common stem (e.g. {run, runned, running} --> \"run\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RamgdDXU9IPq"
      },
      "source": [
        "We start creating a `PorterStemmer` object, providing a `stem` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmpatPc29IPr"
      },
      "outputs": [],
      "source": [
        "ps = nltk.stem.PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc0qOEK9IPr",
        "outputId": "4628488c-63a2-48ba-883f-6abf2aa34dda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('stem', 'stem')"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.stem(\"stem\"), ps.stem(\"stemming\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl_591k6v6TZ",
        "outputId": "bb3efcc6-f429-4e80-f158-d9c9eee9f95d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('run', 'run', 'run')"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.stem(\"run\"), ps.stem(\"runned\"), ps.stem(\"running\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwlX4rHf9IPt"
      },
      "source": [
        "We can use that to create a function which uses NLTK to tokenize text into words and return a sequence of stems instead of complete words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZStwuomf9IPu"
      },
      "outputs": [],
      "source": [
        "def tokenize_with_stemming(text):\n",
        "    return [ps.stem(token) for token # for each word in the tokenized text apply the ps.stem() function\n",
        "        in nltk.tokenize.word_tokenize(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZxdVWzM9IPv",
        "outputId": "c2aaf229-e9fa-423b-c2f1-ef626f43b13a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['we', 'have', 'shown', 'mani', 'exampl', '!']"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize_with_stemming(\"We have shown many examples!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIs6UWap9IPw"
      },
      "source": [
        "In a vectorizer, we can set the `tokenizer` parameter to use our custom tokenization function in place of scikit-learn default one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie7GW6VM9IPw"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_stemming)),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oxp_WkP9IPx"
      },
      "source": [
        "We can then fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guFzXQvr9IPx",
        "outputId": "5a067146-779e-47d6-bb6f-1d41115a1814"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dMVXv-9IPy"
      },
      "source": [
        "The number of feature is further reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_35EZ_i69IPy",
        "outputId": "4225c0ed-6567-43f2-e6e9-e2b674a40227"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12516"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iysRIvF9IPz"
      },
      "source": [
        "Computing the accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYBlI3gx9IPz",
        "outputId": "bfa016aa-d45b-4d8c-f600-9b22d4e7b8eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8398"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbXQzbdz9IP0"
      },
      "source": [
        "...we see in this case a minor loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6QpBeJP9IP0"
      },
      "source": [
        "### n-grams\n",
        "\n",
        "An _n-gram_ is a sequence of n consecutive words in a text: in the common cases with n equal to 2 and 3, they are called _bigrams_ and _trigrams_\n",
        "\n",
        "n-grams can be used in addition or replacement to single words as features to represent reviews: they can be **useful to spot meaningful expressions composed of more than one word**, although we will also get many n-grams with no significant meaning\n",
        "\n",
        "For example, in the sentence \"Sentiment analysis is not bad\" we have meaningful bigrams indicating a concept (\"Sentiment analysis\") and an opinion (\"not bad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObnuLgHv9IP0"
      },
      "source": [
        "Setting the `ngram_range` parameter of a vectorizer to a tuple `(a,b)`, it will use as features all n-grams with n between a and b; the default value is `(1, 1)`, meaning that only single words (\"1-grams\") are considered\n",
        "\n",
        "Let's see what happens by setting `(1, 2)`, i.e. considering both single words and bigrams, still limiting features to those appearing in 3 reviews at least"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsRwMuQR9IP0"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))), # using 1-grams and 2-grams\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSOpCexo9IP1"
      },
      "source": [
        "Fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha-KoggH9IP1"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]); #reviews_train.text = reviews_train[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-_TiXu9IP4"
      },
      "source": [
        "Adding bigrams to single words, the dimensionality is sensibly higher..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA6B_k8q9IP4",
        "outputId": "41ec6ee9-08d2-4130-ce10-d1e38adf201e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "71800"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names_out()) # \"sentiment\" + \"sentiment analysis\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1Xe-wy9IP5"
      },
      "source": [
        "...but in this case we successfully increase the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKZ1Eq_9IP5",
        "outputId": "12f42da8-486d-4408-be77-86a4689d0279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.851"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test[\"text\"], reviews_test[\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_k_q0uh9IP5"
      },
      "source": [
        "### Sentiment analysis with NLTK\n",
        "\n",
        "NLTK integrates specific functions for sentiment analysis, allowing to evaluate the subjectivity and the sentiment of text\n",
        "\n",
        "Let's see for example how to classify reviews using VADER (_Valence Aware Dictionary for sEntiment Reasoning_), a lexicon and rule-based sentiment estimator specifically oriented to social media, of which NLTK provides an implementation\n",
        "\n",
        "- **Reference:** Hutto, C. J., and Eric Gilbert. \"VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text.\" _Eighth International AAAI Conference on Weblogs and Social Media_. 2014."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCSzAi59IP6"
      },
      "source": [
        "Download the necessary data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmAuvsax9IP6",
        "outputId": "d91995fc-7a78-46fd-e52f-8a8cc110ae7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"vader_lexicon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_-UnfYU9IP6"
      },
      "source": [
        "Import the class and create an analyzer object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNOc25rqu1GP",
        "outputId": "9b0741ec-a8ba-4b3b-a3d8-497a15114f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from twython) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from twython) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->twython) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->twython) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->twython) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->twython) (2023.11.17)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.2.2)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install twython # nltk.sentiment dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnZ6wPt_9IP6"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoLmF1HV9IP7"
      },
      "source": [
        "We can see some words in the VADER lexicon along with the positive or negative orientation assigned to them: we can see that typical social media language is recognized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5T7h5oA9IP7",
        "outputId": "93397745-f708-438a-d73d-d3bc6858f5b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.7"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"excellent\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOoK2PH9IP8",
        "outputId": "99cc0f73-c400-40b5-8200-864dc02af3e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.5"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"sux\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGFlq5j59IP8",
        "outputId": "8118c838-15af-4761-d585-8fd72906293e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-2.8"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"wtf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-AOTKC9IP9",
        "outputId": "dd28372b-2e8a-4915-dfbe-eff6ae901f89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.3"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\":-)\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwkZwp419IP_"
      },
      "source": [
        "Using the `polarity_score` method, given some text, we obtain a dictionary stating the probability of the sentence being either positive, negative or sentiment-neutral.\n",
        "\n",
        "The `compound` score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-Tk-NI9IP_",
        "outputId": "e97e1cc0-908d-4985-fdaa-4bb3b19bac82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.412, 'pos': 0.588, 'compound': 0.431}"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"Not a bad movie\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMFpr1YA9IQA",
        "outputId": "227fbb49-ce15-4cea-8613-e65cdf656c0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.413, 'neu': 0.587, 'pos': 0.0, 'compound': -0.2755}"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"I wouldn't recommend this movie\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-28eatr59IQC",
        "outputId": "0eb9400b-46ed-428b-863c-70438a8de1a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.4588}"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"This movie is candidated to 3 Academy awards\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnBSC1np9IQE"
      },
      "source": [
        "We can see that the model is reasonably good in detecting compound statements such as negations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6s63IFF9IQE"
      },
      "source": [
        "Let's create a function that, given a review, returns a \"pos\" or \"neg\" label according to VADER scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNMhwi1i9IQE"
      },
      "outputs": [],
      "source": [
        "def vader_classify(text):\n",
        "    scores = vader.polarity_scores(text)\n",
        "    return \"pos\" if scores[\"pos\"] >= scores[\"neg\"] else \"neg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW-iJVP-9IQF"
      },
      "source": [
        "Using the `apply` method of series, we apply the function to each review text obtaining a series of pos/neg labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUtWVwWa9IQF"
      },
      "outputs": [],
      "source": [
        "vader_preds = reviews_test[\"text\"].apply(vader_classify)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIS92sBh9IQH"
      },
      "source": [
        "We compare this series with actual labels, obtaining a boolean series stating for which reviews the classifier indicated the correct label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPTLs0SR9IQH"
      },
      "outputs": [],
      "source": [
        "vader_hits = vader_preds == reviews_test[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9_JcA9v9IQJ",
        "outputId": "a44304a6-6bc1-46e8-a457-033491edc02b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True, False,  True])"
            ]
          },
          "execution_count": 219,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader_hits.values[:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWYLf4HU9IQL"
      },
      "source": [
        "Computing the mean, we obtain the ratio of `True` values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT_IrQIf9IQL",
        "outputId": "eaaad802-0bee-4d9e-856a-6e97985bcc56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6948"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader_hits.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSM4e3_9IQM"
      },
      "source": [
        "Here VADER achieves a lower accuracy than our supervised model, which however required a large set of pre-labeled reviews to be trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKe42xjW9IQM"
      },
      "source": [
        "### 👨‍💻 Exercise 2: test new methods on tweets\n",
        "\n",
        "In this activity we have seen two sentiment classification methods\n",
        "- using a classifier trained on the labeled movie reviews (supervised)\n",
        "- using the pretrained VADER model (unsupervised)\n",
        "\n",
        "Test both these new methods on airline tweets from Activity 1, giving each tweet a score of -5 or 5 according to the negative or positive response of the classifier, then compare summary scores obtained by both methods with ACSI scores\n",
        "\n",
        "Which of the two methods do you expect to be more accurate?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Qr17VRMp9IOw"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
